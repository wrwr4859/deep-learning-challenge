{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "VopUYnWMKgNs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "BgydiPYMfezw",
        "outputId": "95262662-14f5-417a-800f-db6b7de29d4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-833fefee-335f-4f6d-ac90-7ee5763cccfc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-833fefee-335f-4f6d-ac90-7ee5763cccfc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-833fefee-335f-4f6d-ac90-7ee5763cccfc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-833fefee-335f-4f6d-ac90-7ee5763cccfc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c555acb-0f52-435c-96f9-d9b60f2a89f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c555acb-0f52-435c-96f9-d9b60f2a89f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c555acb-0f52-435c-96f9-d9b60f2a89f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "application_df",
              "summary": "{\n  \"name\": \"application_df\",\n  \"rows\": 34299,\n  \"fields\": [\n    {\n      \"column\": \"EIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 245147183,\n        \"min\": 10520599,\n        \"max\": 996086871,\n        \"num_unique_values\": 34299,\n        \"samples\": [\n          271598055,\n          900109768,\n          352562499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19568,\n        \"samples\": [\n          \"LOCAL 12 USW GOODYEAR INSTITUTE FORCAREER DEVELOPMENT\",\n          \"INTERNATION ASSOCIATION OF ELECTRICAL INSPECTORS\",\n          \"BRICKLAYERS & ALLIED CRAFTWORKERS LOCAL 13 VACATION FUND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"APPLICATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"T10\",\n          \"T3\",\n          \"T6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AFFILIATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Independent\",\n          \"CompanySponsored\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"C1500\",\n          \"C1000\",\n          \"C1570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USE_CASE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Preservation\",\n          \"Other\",\n          \"Heathcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORGANIZATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Co-operative\",\n          \"Corporation\",\n          \"Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STATUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INCOME_AMT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1M-5M\",\n          \"1-9999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPECIAL_CONSIDERATIONS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASK_AMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87130452,\n        \"min\": 5000,\n        \"max\": 8597806340,\n        \"num_unique_values\": 8747,\n        \"samples\": [\n          1328927,\n          42942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IS_SUCCESSFUL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Import dependencies\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Step 1: Preprocess the Data<h2>"
      ],
      "metadata": {
        "id": "UHiJCUBOh0bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "#  YOUR CODE GOES HERE\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1p4pUE4DffSs",
        "outputId": "b06b4fe8-5583-453b-b922-21beb4f92bce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0              T10       Independent          C1000    ProductDev   \n",
              "1               T3       Independent          C2000  Preservation   \n",
              "2               T5  CompanySponsored          C3000    ProductDev   \n",
              "3               T3  CompanySponsored          C2000  Preservation   \n",
              "4               T3       Independent          C1000     Heathcare   \n",
              "\n",
              "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
              "0   Association       1              0                      N     5000   \n",
              "1  Co-operative       1         1-9999                      N   108590   \n",
              "2   Association       1              0                      N     5000   \n",
              "3         Trust       1    10000-24999                      N     6692   \n",
              "4         Trust       1  100000-499999                      N   142590   \n",
              "\n",
              "   IS_SUCCESSFUL  \n",
              "0              1  \n",
              "1              1  \n",
              "2              0  \n",
              "3              1  \n",
              "4              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5516f4e6-c1f1-4c6a-b041-06bb15ca6799\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5516f4e6-c1f1-4c6a-b041-06bb15ca6799')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5516f4e6-c1f1-4c6a-b041-06bb15ca6799 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5516f4e6-c1f1-4c6a-b041-06bb15ca6799');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf78fed7-b537-4913-9c68-de8ac0a03cd2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf78fed7-b537-4913-9c68-de8ac0a03cd2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf78fed7-b537-4913-9c68-de8ac0a03cd2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "application_df",
              "summary": "{\n  \"name\": \"application_df\",\n  \"rows\": 34299,\n  \"fields\": [\n    {\n      \"column\": \"APPLICATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"T10\",\n          \"T3\",\n          \"T6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AFFILIATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Independent\",\n          \"CompanySponsored\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"C1500\",\n          \"C1000\",\n          \"C1570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USE_CASE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Preservation\",\n          \"Other\",\n          \"Heathcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORGANIZATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Co-operative\",\n          \"Corporation\",\n          \"Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STATUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INCOME_AMT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1M-5M\",\n          \"1-9999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPECIAL_CONSIDERATIONS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASK_AMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87130452,\n        \"min\": 5000,\n        \"max\": 8597806340,\n        \"num_unique_values\": 8747,\n        \"samples\": [\n          1328927,\n          42942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IS_SUCCESSFUL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>What variable(s) are the target(s) for your model?<h3>\n",
        "<h4>IS_SUCCESSFUL<h4>\n",
        "\n",
        "<h3>What variable(s) are the feature(s) for your model? <h3>\n",
        "<h4>APPLICATION_TYPE, AFFILIATION, CLASSIFICATION, USE_CASE, ORGANIZATION, STATUS, INCOME_AMT, SPECIAL_CONSIDERATIONS, ASK_AMT<h4>"
      ],
      "metadata": {
        "id": "H177fNzFgcBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique values in each column.\n",
        "#  YOUR CODE GOES HERE\n",
        "application_df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "TWaNEiSzffU_",
        "outputId": "e2746695-0c2c-4451-94fe-4ae6d4eee2c9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFFILIATION</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USE_CASE</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STATUS</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASK_AMT</th>\n",
              "      <td>8747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
        "#  YOUR CODE GOES HERE\n",
        "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "print(application_counts)"
      ],
      "metadata": {
        "id": "s2cnxTgNffXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368dde75-ca7a-4554-df2e-ca784e1328c8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE\n",
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "#  YOUR CODE GOES HERE\n",
        "application_types_to_replace = application_counts[application_counts < 200].index\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "id": "js1hXbR5f1gG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "759e7017-975c-4f79-e034-d491034abb7d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T3</th>\n",
              "      <td>27037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4</th>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T6</th>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T5</th>\n",
              "      <td>1173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T19</th>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T8</th>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T7</th>\n",
              "      <td>725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T10</th>\n",
              "      <td>528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
        "#  YOUR CODE GOES HERE\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "print(classification_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ8dzcgkFp0H",
        "outputId": "939a3869-4ce8-45c4-bb69-517829e583b1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C4120        1\n",
            "C8210        1\n",
            "C2561        1\n",
            "C4500        1\n",
            "C2150        1\n",
            "Name: count, Length: 71, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "#  YOUR CODE GOES HERE\n",
        "# Get the counts of unique values in 'CLASSIFICATION'\n",
        "greaterthanone = classification_counts[classification_counts > 1]\n",
        "greaterthanone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fjK8Wk8Hf1kw",
        "outputId": "c35a517c-e29d-4c6e-cab9-691cff9b0df1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1700</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4000</th>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C5000</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1270</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2700</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2800</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7100</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1300</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1280</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1230</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1400</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7200</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2300</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1240</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8000</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7120</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1500</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1800</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C6000</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1250</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8200</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1238</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1278</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1235</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1237</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7210</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2400</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1720</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4100</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1257</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1600</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1260</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2710</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3200</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1234</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1246</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1267</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1256</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "#  YOUR CODE GOES HERE\n",
        "classification_to_replace = classification_counts[classification_counts < 600].index\n",
        "# Replace in dataframe\n",
        "for cls in classification_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "id": "P8aZEgaXf1nH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "344f6e73-7008-4216-8283-568b16c0a56a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>1484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "#  YOUR CODE GOES HERE\n",
        "application_df = pd.get_dummies(application_df)"
      ],
      "metadata": {
        "id": "pMkM2F4jgCLr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "#  YOUR CODE GOES HERE\n",
        "X = application_df.drop('IS_SUCCESSFUL', axis=1).values\n",
        "y = application_df['IS_SUCCESSFUL'].values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "#  YOUR CODE GOES HERE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "nUQ9u1EXgCNw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kjgUNB94gCQF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of input features\n",
        "input_features = X_train_scaled.shape[1]\n",
        "print(f'Number of input features: {input_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsqIPRRsJz_O",
        "outputId": "278d1448-6062-4404-dcbe-49a8a09d4944"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input features: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check class balance which looks fine\n",
        "sns.countplot(x=application_df['IS_SUCCESSFUL'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "O3rG-yuEuLli",
        "outputId": "74c8b236-6ec6-4563-9047-cb624f62352f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='IS_SUCCESSFUL', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAygklEQVR4nO3de1hVdb7H8c9GY6OjgDfYUKRkCqmoSUU0k2kxoDmVk2OllpakY6OZ4ihDY4pZQ6ORWlaMpzHqGTyWXajMYyJ5qaSLKN5KjhqOenKjU8pOVG7u80eHddqDl58I7Y29X8+znof1+333Wt8fPeTnWWuxsLndbrcAAABwVn7ebgAAAKApIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYaO7tBi4Wp06d0jfffKPWrVvLZrN5ux0AAGDA7Xbr+++/V3h4uPz8zn4tidDUQL755htFRER4uw0AAFAP+/fv12WXXXbWGkJTA2ndurWkH77pgYGBXu4GAACYcLlcioiIsP4dPxtCUwOpvSUXGBhIaAIAoIkxebSGB8EBAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMNPd2AwCAH8ROfdXbLQA+p3DuSG+3YOFKEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAGvhqb169frtttuU3h4uGw2m3Jzcz3mbTbbabe5c+daNZ06daoz/9RTT3kcZ+vWrbrxxhsVEBCgiIgIzZkzp04vy5YtU3R0tAICAhQTE6MVK1Y0ypoBAEDT5NXQVF5erl69eun5558/7fzBgwc9tsWLF8tms2nIkCEedY8//rhH3cMPP2zNuVwuJSYmqmPHjiosLNTcuXOVnp6uRYsWWTUbNmzQsGHDlJycrM2bN2vw4MEaPHiwtm/f3jgLBwAATY5X/2DvwIEDNXDgwDPOOxwOj/133nlH/fv31xVXXOEx3rp16zq1tXJyclRZWanFixfL399f3bt3V1FRkZ555hmNHTtWkrRgwQINGDBAU6dOlSTNnj1beXl5WrhwobKysk573IqKClVUVFj7Lpfr3AsGAABNVpN5pqm0tFTvv/++kpOT68w99dRTateuna6++mrNnTtX1dXV1lxBQYH69u0rf39/aywpKUnFxcU6cuSIVZOQkOBxzKSkJBUUFJyxn4yMDAUFBVlbRETEhS4RAAD4sCYTml555RW1bt1ad955p8f4xIkTtXTpUq1Zs0a///3v9Ze//EXTpk2z5p1Op0JDQz0+U7vvdDrPWlM7fzppaWkqKyuztv3791/Q+gAAgG/z6u2587F48WKNGDFCAQEBHuMpKSnW1z179pS/v79+//vfKyMjQ3a7vdH6sdvtjXp8AADgW5rElaaPPvpIxcXFevDBB89ZGxcXp+rqau3du1fSD89FlZaWetTU7tc+B3WmmjM9JwUAAH5+mkRo+vvf/67Y2Fj16tXrnLVFRUXy8/NTSEiIJCk+Pl7r169XVVWVVZOXl6eoqCi1adPGqsnPz/c4Tl5enuLj4xtwFQAAoCnzamg6duyYioqKVFRUJEkqKSlRUVGR9u3bZ9W4XC4tW7bstFeZCgoKNH/+fG3ZskVff/21cnJyNHnyZN17771WIBo+fLj8/f2VnJysHTt26LXXXtOCBQs8bus98sgjWrlypTIzM7Vz506lp6dr48aNmjBhQuN+AwAAQJPh1WeaNm7cqP79+1v7tUFm1KhRys7OliQtXbpUbrdbw4YNq/N5u92upUuXKj09XRUVFYqMjNTkyZM9AlFQUJBWrVql8ePHKzY2Vu3bt9eMGTOs1w1I0g033KAlS5Zo+vTpevTRR9WlSxfl5uaqR48ejbRyAADQ1Njcbrfb201cDFwul4KCglRWVqbAwEBvtwOgCYqd+qq3WwB8TuHckY16/PP597tJPNMEAADgbYQmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA8293QDOT+zUV73dAuBzCueO9HYLAH4GuNIEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABgwKuhaf369brtttsUHh4um82m3Nxcj/n7779fNpvNYxswYIBHzXfffacRI0YoMDBQwcHBSk5O1rFjxzxqtm7dqhtvvFEBAQGKiIjQnDlz6vSybNkyRUdHKyAgQDExMVqxYkWDrxcAADRdXg1N5eXl6tWrl55//vkz1gwYMEAHDx60tv/8z//0mB8xYoR27NihvLw8LV++XOvXr9fYsWOteZfLpcTERHXs2FGFhYWaO3eu0tPTtWjRIqtmw4YNGjZsmJKTk7V582YNHjxYgwcP1vbt2xt+0QAAoElq7s2TDxw4UAMHDjxrjd1ul8PhOO3cV199pZUrV+qLL77QNddcI0l67rnndOutt+rpp59WeHi4cnJyVFlZqcWLF8vf31/du3dXUVGRnnnmGStcLViwQAMGDNDUqVMlSbNnz1ZeXp4WLlyorKysBlwxAABoqnz+maa1a9cqJCREUVFReuihh/Ttt99acwUFBQoODrYCkyQlJCTIz89Pn332mVXTt29f+fv7WzVJSUkqLi7WkSNHrJqEhASP8yYlJamgoOCMfVVUVMjlcnlsAADg4uXToWnAgAF69dVXlZ+fr7/+9a9at26dBg4cqJqaGkmS0+lUSEiIx2eaN2+utm3byul0WjWhoaEeNbX756qpnT+djIwMBQUFWVtERMSFLRYAAPg0r96eO5d77rnH+jomJkY9e/ZU586dtXbtWt1yyy1e7ExKS0tTSkqKte9yuQhOAABcxHz6StO/u+KKK9S+fXvt3r1bkuRwOHTo0CGPmurqan333XfWc1AOh0OlpaUeNbX756o507NU0g/PWgUGBnpsAADg4tWkQtOBAwf07bffKiwsTJIUHx+vo0ePqrCw0Kr58MMPderUKcXFxVk169evV1VVlVWTl5enqKgotWnTxqrJz8/3OFdeXp7i4+Mbe0kAAKCJ8GpoOnbsmIqKilRUVCRJKikpUVFRkfbt26djx45p6tSp+vTTT7V3717l5+frjjvu0JVXXqmkpCRJ0lVXXaUBAwZozJgx+vzzz/XJJ59owoQJuueeexQeHi5JGj58uPz9/ZWcnKwdO3botdde04IFCzxurT3yyCNauXKlMjMztXPnTqWnp2vjxo2aMGHCT/49AQAAvsmroWnjxo26+uqrdfXVV0uSUlJSdPXVV2vGjBlq1qyZtm7dqttvv11du3ZVcnKyYmNj9dFHH8lut1vHyMnJUXR0tG655Rbdeuut+tWvfuXxDqagoCCtWrVKJSUlio2N1ZQpUzRjxgyPdzndcMMNWrJkiRYtWqRevXrpjTfeUG5urnr06PHTfTMAAIBPs7ndbre3m7gYuFwuBQUFqaysrFGfb4qd+mqjHRtoqgrnjvR2Cw2Cn2+grsb++T6ff7+b1DNNAAAA3kJoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMODV0LR+/XrddtttCg8Pl81mU25urjVXVVWl1NRUxcTE6Be/+IXCw8M1cuRIffPNNx7H6NSpk2w2m8f21FNPedRs3bpVN954owICAhQREaE5c+bU6WXZsmWKjo5WQECAYmJitGLFikZZMwAAaJq8GprKy8vVq1cvPf/883Xmjh8/rk2bNumxxx7Tpk2b9NZbb6m4uFi33357ndrHH39cBw8etLaHH37YmnO5XEpMTFTHjh1VWFiouXPnKj09XYsWLbJqNmzYoGHDhik5OVmbN2/W4MGDNXjwYG3fvr1xFg4AAJqc5t48+cCBAzVw4MDTzgUFBSkvL89jbOHChbruuuu0b98+XX755dZ469at5XA4TnucnJwcVVZWavHixfL391f37t1VVFSkZ555RmPHjpUkLViwQAMGDNDUqVMlSbNnz1ZeXp4WLlyorKyshlgqAABo4prUM01lZWWy2WwKDg72GH/qqafUrl07XX311Zo7d66qq6utuYKCAvXt21f+/v7WWFJSkoqLi3XkyBGrJiEhweOYSUlJKigoOGMvFRUVcrlcHhsAALh4efVK0/k4efKkUlNTNWzYMAUGBlrjEydOVJ8+fdS2bVtt2LBBaWlpOnjwoJ555hlJktPpVGRkpMexQkNDrbk2bdrI6XRaYz+ucTqdZ+wnIyNDs2bNaqjlAQAAH9ckQlNVVZXuuusuud1uvfjiix5zKSkp1tc9e/aUv7+/fv/73ysjI0N2u73RekpLS/M4t8vlUkRERKOdDwAAeJfPh6bawPTPf/5TH374ocdVptOJi4tTdXW19u7dq6ioKDkcDpWWlnrU1O7XPgd1ppozPSclSXa7vVFDGQAA8C0+/UxTbWDatWuXVq9erXbt2p3zM0VFRfLz81NISIgkKT4+XuvXr1dVVZVVk5eXp6ioKLVp08aqyc/P9zhOXl6e4uPjG3A1AACgKfPqlaZjx45p9+7d1n5JSYmKiorUtm1bhYWF6Xe/+502bdqk5cuXq6amxnrGqG3btvL391dBQYE+++wz9e/fX61bt1ZBQYEmT56se++91wpEw4cP16xZs5ScnKzU1FRt375dCxYs0Lx586zzPvLII7rpppuUmZmpQYMGaenSpdq4caPHawkAAMDPm1dD08aNG9W/f39rv/YZoVGjRik9PV3vvvuuJKl3794en1uzZo369esnu92upUuXKj09XRUVFYqMjNTkyZM9njUKCgrSqlWrNH78eMXGxqp9+/aaMWOG9boBSbrhhhu0ZMkSTZ8+XY8++qi6dOmi3Nxc9ejRoxFXDwAAmhKvhqZ+/frJ7Xafcf5sc5LUp08fffrpp+c8T8+ePfXRRx+dtWbo0KEaOnToOY8FAAB+nnz6mSYAAABfQWgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwUK/QdPPNN+vo0aN1xl0ul26++eYL7QkAAMDn1Cs0rV27VpWVlXXGT548qY8++uiCmwIAAPA1zc+neOvWrdbXX375pZxOp7VfU1OjlStX6tJLL2247gAAAHzEeYWm3r17y2azyWaznfY2XIsWLfTcc881WHMAAAC+4rxCU0lJidxut6644gp9/vnn6tChgzXn7++vkJAQNWvWrMGbBAAA8LbzeqapY8eO6tSpk06dOqVrrrlGHTt2tLawsLDzDkzr16/XbbfdpvDwcNlsNuXm5nrMu91uzZgxQ2FhYWrRooUSEhK0a9cuj5rvvvtOI0aMUGBgoIKDg5WcnKxjx4551GzdulU33nijAgICFBERoTlz5tTpZdmyZYqOjlZAQIBiYmK0YsWK81oLAAC4uJ3XlaYf27Vrl9asWaNDhw7p1KlTHnMzZswwOkZ5ebl69eql0aNH684776wzP2fOHD377LN65ZVXFBkZqccee0xJSUn68ssvFRAQIEkaMWKEDh48qLy8PFVVVemBBx7Q2LFjtWTJEkk//EZfYmKiEhISlJWVpW3btmn06NEKDg7W2LFjJUkbNmzQsGHDlJGRod/85jdasmSJBg8erE2bNqlHjx71/RYBAICLiM3tdrvP90P/8R//oYceekjt27eXw+GQzWb7/wPabNq0adP5N2Kz6e2339bgwYMl/XCVKTw8XFOmTNEf//hHSVJZWZlCQ0OVnZ2te+65R1999ZW6deumL774Qtdcc40kaeXKlbr11lt14MABhYeH68UXX9Sf//xnOZ1O+fv7S5L+9Kc/KTc3Vzt37pQk3X333SovL9fy5cutfq6//nr17t1bWVlZRv27XC4FBQWprKxMgYGB571+U7FTX220YwNNVeHckd5uoUHw8w3U1dg/3+fz73e9XjnwxBNP6Mknn5TT6VRRUZE2b95sbfUJTKdTUlIip9OphIQEaywoKEhxcXEqKCiQJBUUFCg4ONgKTJKUkJAgPz8/ffbZZ1ZN3759rcAkSUlJSSouLtaRI0esmh+fp7am9jynU1FRIZfL5bEBAICLV71C05EjRzR06NCG7sVD7esMQkNDPcZDQ0OtOafTqZCQEI/55s2bq23bth41pzvGj89xppofv1Lh32VkZCgoKMjaIiIizneJAACgCalXaBo6dKhWrVrV0L00KWlpaSorK7O2/fv3e7slAADQiOr1IPiVV16pxx57TJ9++qliYmJ0ySWXeMxPnDjxghtzOBySpNLSUoWFhVnjpaWl6t27t1Vz6NAhj89VV1fru+++sz7vcDhUWlrqUVO7f66a2vnTsdvtstvt9VgZAABoiuoVmhYtWqRWrVpp3bp1WrdunceczWZrkNAUGRkph8Oh/Px8KyS5XC599tlneuihhyRJ8fHxOnr0qAoLCxUbGytJ+vDDD3Xq1CnFxcVZNX/+859VVVVlhbu8vDxFRUWpTZs2Vk1+fr4mTZpknT8vL0/x8fEXvA4AAHBxqFdoKikpaZCTHzt2TLt37/Y4blFRkdq2bavLL79ckyZN0hNPPKEuXbpYrxwIDw+3fsPuqquu0oABAzRmzBhlZWWpqqpKEyZM0D333KPw8HBJ0vDhwzVr1iwlJycrNTVV27dv14IFCzRv3jzrvI888ohuuukmZWZmatCgQVq6dKk2btyoRYsWNcg6AQBA01fv9zQ1hI0bN6p///7WfkpKiiRp1KhRys7O1rRp01ReXq6xY8fq6NGj+tWvfqWVK1da72iSpJycHE2YMEG33HKL/Pz8NGTIED377LPWfFBQkFatWqXx48crNjZW7du314wZM6x3NEnSDTfcoCVLlmj69Ol69NFH1aVLF+Xm5vKOJgAAYKnXe5pGjx591vnFixfXu6Gmivc0Ad7De5qAi5cvvaepXleaat9vVKuqqkrbt2/X0aNHT/uHfAEAAJq6eoWmt99+u87YqVOn9NBDD6lz584X3BQAAICvqdd7mk57ID8/paSkeDxgDQAAcLFosNAkSXv27FF1dXVDHhIAAMAn1Ov2XO1vudVyu906ePCg3n//fY0aNapBGgMAAPAl9QpNmzdv9tj38/NThw4dlJmZec7frAMAAGiK6hWa1qxZ09B9AAAA+LQLernl4cOHVVxcLEmKiopShw4dGqQpAAAAX1OvB8HLy8s1evRohYWFqW/fvurbt6/Cw8OVnJys48ePN3SPAAAAXlev0JSSkqJ169bpvffe09GjR3X06FG98847WrdunaZMmdLQPQIAAHhdvW7Pvfnmm3rjjTfUr18/a+zWW29VixYtdNddd+nFF19sqP4AAAB8Qr2uNB0/flyhoaF1xkNCQrg9BwAALkr1Ck3x8fGaOXOmTp48aY2dOHFCs2bNUnx8fIM1BwAA4CvqdXtu/vz5GjBggC677DL16tVLkrRlyxbZ7XatWrWqQRsEAADwBfUKTTExMdq1a5dycnK0c+dOSdKwYcM0YsQItWjRokEbBAAA8AX1Ck0ZGRkKDQ3VmDFjPMYXL16sw4cPKzU1tUGaAwAA8BX1eqbpb3/7m6Kjo+uMd+/eXVlZWRfcFAAAgK+pV2hyOp0KCwurM96hQwcdPHjwgpsCAADwNfUKTREREfrkk0/qjH/yyScKDw+/4KYAAAB8Tb2eaRozZowmTZqkqqoq3XzzzZKk/Px8TZs2jTeCAwCAi1K9QtPUqVP17bff6g9/+IMqKyslSQEBAUpNTVVaWlqDNggAAOAL6hWabDab/vrXv+qxxx7TV199pRYtWqhLly6y2+0N3R8AAIBPqFdoqtWqVStde+21DdULAACAz6rXg+AAAAA/N4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAAz4fmjp16iSbzVZnGz9+vCSpX79+debGjRvncYx9+/Zp0KBBatmypUJCQjR16lRVV1d71Kxdu1Z9+vSR3W7XlVdeqezs7J9qiQAAoAlo7u0GzuWLL75QTU2Ntb99+3b9+te/1tChQ62xMWPG6PHHH7f2W7ZsaX1dU1OjQYMGyeFwaMOGDTp48KBGjhypSy65RH/5y18kSSUlJRo0aJDGjRunnJwc5efn68EHH1RYWJiSkpJ+glUCAABf5/OhqUOHDh77Tz31lDp37qybbrrJGmvZsqUcDsdpP79q1Sp9+eWXWr16tUJDQ9W7d2/Nnj1bqampSk9Pl7+/v7KyshQZGanMzExJ0lVXXaWPP/5Y8+bNO2NoqqioUEVFhbXvcrkudKkAAMCH+fztuR+rrKzUP/7xD40ePVo2m80az8nJUfv27dWjRw+lpaXp+PHj1lxBQYFiYmIUGhpqjSUlJcnlcmnHjh1WTUJCgse5kpKSVFBQcMZeMjIyFBQUZG0RERENtUwAAOCDfP5K04/l5ubq6NGjuv/++62x4cOHq2PHjgoPD9fWrVuVmpqq4uJivfXWW5Ikp9PpEZgkWftOp/OsNS6XSydOnFCLFi3q9JKWlqaUlBRr3+VyEZwAALiINanQ9Pe//10DBw5UeHi4NTZ27Fjr65iYGIWFhemWW27Rnj171Llz50brxW63y263N9rxAQCAb2kyt+f++c9/avXq1XrwwQfPWhcXFydJ2r17tyTJ4XCotLTUo6Z2v/Y5qDPVBAYGnvYqEwAA+PlpMqHp5ZdfVkhIiAYNGnTWuqKiIklSWFiYJCk+Pl7btm3ToUOHrJq8vDwFBgaqW7duVk1+fr7HcfLy8hQfH9+AKwAAAE1ZkwhNp06d0ssvv6xRo0apefP/v6O4Z88ezZ49W4WFhdq7d6/effddjRw5Un379lXPnj0lSYmJierWrZvuu+8+bdmyRR988IGmT5+u8ePHW7fXxo0bp6+//lrTpk3Tzp079cILL+j111/X5MmTvbJeAADge5pEaFq9erX27dun0aNHe4z7+/tr9erVSkxMVHR0tKZMmaIhQ4bovffes2qaNWum5cuXq1mzZoqPj9e9996rkSNHerzXKTIyUu+//77y8vLUq1cvZWZm6qWXXuIdTQAAwNIkHgRPTEyU2+2uMx4REaF169ad8/MdO3bUihUrzlrTr18/bd68ud49AgCAi1uTuNIEAADgbYQmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAAz4dmtLT02Wz2Ty26Ohoa/7kyZMaP3682rVrp1atWmnIkCEqLS31OMa+ffs0aNAgtWzZUiEhIZo6daqqq6s9atauXas+ffrIbrfryiuvVHZ29k+xPAAA0IT4dGiSpO7du+vgwYPW9vHHH1tzkydP1nvvvadly5Zp3bp1+uabb3TnnXda8zU1NRo0aJAqKyu1YcMGvfLKK8rOztaMGTOsmpKSEg0aNEj9+/dXUVGRJk2apAcffFAffPDBT7pOAADg25p7u4Fzad68uRwOR53xsrIy/f3vf9eSJUt08803S5JefvllXXXVVfr00091/fXXa9WqVfryyy+1evVqhYaGqnfv3po9e7ZSU1OVnp4uf39/ZWVlKTIyUpmZmZKkq666Sh9//LHmzZunpKSkM/ZVUVGhiooKa9/lcjXwygEAgC/x+StNu3btUnh4uK644gqNGDFC+/btkyQVFhaqqqpKCQkJVm10dLQuv/xyFRQUSJIKCgoUExOj0NBQqyYpKUkul0s7duywan58jNqa2mOcSUZGhoKCgqwtIiKiQdYLAAB8k0+Hpri4OGVnZ2vlypV68cUXVVJSohtvvFHff/+9nE6n/P39FRwc7PGZ0NBQOZ1OSZLT6fQITLXztXNnq3G5XDpx4sQZe0tLS1NZWZm17d+//0KXCwAAfJhP354bOHCg9XXPnj0VFxenjh076vXXX1eLFi282Jlkt9tlt9u92gMAAPjp+PSVpn8XHBysrl27avfu3XI4HKqsrNTRo0c9akpLS61noBwOR53fpqvdP1dNYGCg14MZAADwHU0qNB07dkx79uxRWFiYYmNjdckllyg/P9+aLy4u1r59+xQfHy9Jio+P17Zt23To0CGrJi8vT4GBgerWrZtV8+Nj1NbUHgMAAEDy8dD0xz/+UevWrdPevXu1YcMG/fa3v1WzZs00bNgwBQUFKTk5WSkpKVqzZo0KCwv1wAMPKD4+Xtdff70kKTExUd26ddN9992nLVu26IMPPtD06dM1fvx469bauHHj9PXXX2vatGnauXOnXnjhBb3++uuaPHmyN5cOAAB8jE8/03TgwAENGzZM3377rTp06KBf/epX+vTTT9WhQwdJ0rx58+Tn56chQ4aooqJCSUlJeuGFF6zPN2vWTMuXL9dDDz2k+Ph4/eIXv9CoUaP0+OOPWzWRkZF6//33NXnyZC1YsECXXXaZXnrppbO+bgAAAPz82Nxut9vbTVwMXC6XgoKCVFZWpsDAwEY7T+zUVxvt2EBTVTh3pLdbaBD8fAN1NfbP9/n8++3Tt+cAAAB8BaEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAgE+HpoyMDF177bVq3bq1QkJCNHjwYBUXF3vU9OvXTzabzWMbN26cR82+ffs0aNAgtWzZUiEhIZo6daqqq6s9atauXas+ffrIbrfryiuvVHZ2dmMvDwAANCE+HZrWrVun8ePH69NPP1VeXp6qqqqUmJio8vJyj7oxY8bo4MGD1jZnzhxrrqamRoMGDVJlZaU2bNigV155RdnZ2ZoxY4ZVU1JSokGDBql///4qKirSpEmT9OCDD+qDDz74ydYKAAB8W3NvN3A2K1eu9NjPzs5WSEiICgsL1bdvX2u8ZcuWcjgcpz3GqlWr9OWXX2r16tUKDQ1V7969NXv2bKWmpio9PV3+/v7KyspSZGSkMjMzJUlXXXWVPv74Y82bN09JSUmNt0AAANBk+PSVpn9XVlYmSWrbtq3HeE5Ojtq3b68ePXooLS1Nx48ft+YKCgoUExOj0NBQaywpKUkul0s7duywahISEjyOmZSUpIKCgjP2UlFRIZfL5bEBAICLl09fafqxU6dOadKkSfrlL3+pHj16WOPDhw9Xx44dFR4erq1btyo1NVXFxcV66623JElOp9MjMEmy9p1O51lrXC6XTpw4oRYtWtTpJyMjQ7NmzWrQNQIAAN/VZELT+PHjtX37dn388cce42PHjrW+jomJUVhYmG655Rbt2bNHnTt3brR+0tLSlJKSYu27XC5FREQ02vkAAIB3NYnbcxMmTNDy5cu1Zs0aXXbZZWetjYuLkyTt3r1bkuRwOFRaWupRU7tf+xzUmWoCAwNPe5VJkux2uwIDAz02AABw8fLp0OR2uzVhwgS9/fbb+vDDDxUZGXnOzxQVFUmSwsLCJEnx8fHatm2bDh06ZNXk5eUpMDBQ3bp1s2ry8/M9jpOXl6f4+PgGWgkAAGjqfDo0jR8/Xv/4xz+0ZMkStW7dWk6nU06nUydOnJAk7dmzR7Nnz1ZhYaH27t2rd999VyNHjlTfvn3Vs2dPSVJiYqK6deum++67T1u2bNEHH3yg6dOna/z48bLb7ZKkcePG6euvv9a0adO0c+dOvfDCC3r99dc1efJkr60dAAD4Fp8OTS+++KLKysrUr18/hYWFWdtrr70mSfL399fq1auVmJio6OhoTZkyRUOGDNF7771nHaNZs2Zavny5mjVrpvj4eN17770aOXKkHn/8casmMjJS77//vvLy8tSrVy9lZmbqpZde4nUDAADA4tMPgrvd7rPOR0REaN26dec8TseOHbVixYqz1vTr10+bN28+r/4AAMDPh09faQIAAPAVhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhKZ/8/zzz6tTp04KCAhQXFycPv/8c2+3BAAAfACh6Udee+01paSkaObMmdq0aZN69eqlpKQkHTp0yNutAQAALyM0/cgzzzyjMWPG6IEHHlC3bt2UlZWlli1bavHixd5uDQAAeFlzbzfgKyorK1VYWKi0tDRrzM/PTwkJCSooKKhTX1FRoYqKCmu/rKxMkuRyuRq1z5qKE416fKApauyfu58KP99AXY398117fLfbfc5aQtP/+de//qWamhqFhoZ6jIeGhmrnzp116jMyMjRr1qw64xEREY3WI4DTC3punLdbANBIfqqf7++//15BQUFnrSE01VNaWppSUlKs/VOnTum7775Tu3btZLPZvNgZfgoul0sRERHav3+/AgMDvd0OgAbEz/fPi9vt1vfff6/w8PBz1hKa/k/79u3VrFkzlZaWeoyXlpbK4XDUqbfb7bLb7R5jwcHBjdkifFBgYCD/UwUuUvx8/3yc6wpTLR4E/z/+/v6KjY1Vfn6+NXbq1Cnl5+crPj7ei50BAABfwJWmH0lJSdGoUaN0zTXX6LrrrtP8+fNVXl6uBx54wNutAQAALyM0/cjdd9+tw4cPa8aMGXI6nerdu7dWrlxZ5+FwwG63a+bMmXVu0QJo+vj5xpnY3Ca/YwcAAPAzxzNNAAAABghNAAAABghNAAAABghNAAAABghNQD08//zz6tSpkwICAhQXF6fPP//c2y0BuEDr16/XbbfdpvDwcNlsNuXm5nq7JfgYQhNwnl577TWlpKRo5syZ2rRpk3r16qWkpCQdOnTI260BuADl5eXq1auXnn/+eW+3Ah/FKweA8xQXF6drr71WCxculPTDm+MjIiL08MMP609/+pOXuwPQEGw2m95++20NHjzY263Ah3ClCTgPlZWVKiwsVEJCgjXm5+enhIQEFRQUeLEzAEBjIzQB5+Ff//qXampq6rwlPjQ0VE6n00tdAQB+CoQmAAAAA4Qm4Dy0b99ezZo1U2lpqcd4aWmpHA6Hl7oCAPwUCE3AefD391dsbKzy8/OtsVOnTik/P1/x8fFe7AwA0Niae7sBoKlJSUnRqFGjdM011+i6667T/PnzVV5ergceeMDbrQG4AMeOHdPu3but/ZKSEhUVFalt27a6/PLLvdgZfAWvHADqYeHChZo7d66cTqd69+6tZ599VnFxcd5uC8AFWLt2rfr3719nfNSoUcrOzv7pG4LPITQBAAAY4JkmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAA3q/vvv1+DBgyVJhw8f1kMPPaTLL79cdrtdDodDSUlJ+uSTT4yOtWXLFt1+++0KCQlRQECAOnXqpLvvvluHDh2S9MOfvbDZbDp69Gidz3bq1Enz58/3GFuzZo1uvfVWtWvXTi1btlS3bt00ZcoU/c///I9V43a7tWjRIsXFxalVq1YKDg7WNddco/nz5+v48eOSpPT0dNlstjpbdHS0dZySkhINHz5c4eHhCggI0GWXXaY77rhDO3futGrWrVunm2++WW3btlXLli3VpUsXjRo1SpWVlR7r+/dt+vTpkqTs7GwFBwef9ntns9mUm5srSdq7d69sNpuKioqMvu8ATo8/2Aug0QwZMkSVlZV65ZVXdMUVV6i0tFT5+fn69ttvz/nZw4cP65ZbbtFvfvMbffDBBwoODtbevXv17rvvqry8/Lx7+dvf/qY//OEPGjVqlN5880116tRJ+/bt06uvvqrMzEw988wzkqT77rtPb731lqZPn66FCxeqQ4cO2rJli+bPn69OnTpZgbB79+5avXq1xzmaN//hf6lVVVX69a9/raioKL311lsKCwvTgQMH9F//9V9WwPvyyy81YMAAPfzww3r22WfVokUL7dq1S2+++aZqamo8jltcXKzAwEBrv1WrVue9fgAXjtAEoFEcPXpUH330kdauXaubbrpJktSxY0ddd911Rp//5JNPVFZWppdeeskKI5GRkaf9g6rncuDAAU2cOFETJ07UvHnzrPFOnTqpb9++VpB5/fXXlZOTo9zcXN1xxx0edbfffrtcLpc11rx5czkcjtOeb8eOHdqzZ4/y8/PVsWNHST+s/Ze//KVVs2rVKjkcDs2ZM8ca69y5swYMGFDneCEhIWe8ogTgp8PtOQCNolWrVmrVqpVyc3NVUVFx3p93OByqrq7W22+/rQv9u+LLli1TZWWlpk2bdtr52kCSk5OjqKgoj8BUy2azKSgoyOh8HTp0kJ+fn9544406V41qORwOHTx4UOvXrzdbBACvIzQBaBTNmzdXdna2XnnlFQUHB+uXv/ylHn30UW3dutXo89dff70effRRDR8+XO3bt9fAgQM1d+5clZaWnncvu3btUmBgoMLCws5ZFxUVZXTMbdu2WcGwdhs3bpwk6dJLL9Wzzz6rGTNmqE2bNrr55ps1e/Zsff3119bnhw4dqmHDhummm25SWFiYfvvb32rhwoUeV7NqXXbZZR7nMbm9CaDhEZoANJohQ4bom2++0bvvvqsBAwZo7dq16tOnj7Kzs40+/+STT8rpdCorK0vdu3dXVlaWoqOjtW3btvPqw+12y2azGdWZioqKUlFRkcf2+OOPW/Pjx4+X0+lUTk6O4uPjtWzZMnXv3l15eXmSpGbNmunll1/WgQMHNGfOHF166aX6y1/+ou7du+vgwYMe5/roo488ztOmTRvjPgE0HEITgEYVEBCgX//613rssce0YcMG3X///Zo5c6bx59u1a6ehQ4fq6aef1ldffaXw8HA9/fTTkmQ9HF1WVlbnc0ePHrVup3Xt2lVlZWV1wsi/69q1q8dvt52Nv7+/rrzySo8tJCTEo6Z169a67bbb9OSTT2rLli268cYb9cQTT3jUXHrppbrvvvu0cOFC7dixQydPnlRWVpZHTWRkpMd5/Pz8rPWXl5fr1KlTddYuyfh2IgAzhCYAP6lu3brV67ffpB+CSufOna3Pd+nSRX5+fiosLPSo+/rrr1VWVqauXbtKkn73u9/J39/f46HrH6sNGcOHD9d///d/65133qlT43a7TxvOTNW+kuBsa2/Tpo3CwsKMvz9RUVGqrq6u8yqBTZs2SZK1fgANg9+eA9Aovv32Ww0dOlSjR49Wz5491bp1a23cuFFz5sw57YPW/2758uVaunSp7rnnHnXt2lVut1vvvfeeVqxYoZdfflnSD1dyHnzwQU2ZMkXNmzdXTEyM9u/fr9TUVF1//fW64YYbJEkRERGaN2+eJkyYIJfLpZEjR6pTp046cOCAXn31VbVq1UqZmZm666679Pbbb2vYsGGaPn26EhMT1aFDB23btk3z5s3Tww8/bL1yoLq6Wk6n06Nnm82m0NBQFRUVaebMmbrvvvvUrVs3+fv7a926dVq8eLFSU1Ml/fAKhKKiIv32t79V586ddfLkSb366qvasWOHnnvuOaPvcffu3ZWYmKjRo0crMzNTV1xxhYqLizVp0iTdfffduvTSSz3qi4uLT3uMSy65xOh8wM+eGwAa0KhRo9x33HGH++TJk+4//elP7j59+riDgoLcLVu2dEdFRbmnT5/uPn78+DmPs2fPHveYMWPcXbt2dbdo0cIdHBzsvvbaa90vv/yyR92JEyfcM2fOdEdHR7tbtGjhjoyMdI8dO9Z9+PDhOsfMy8tzJyUludu0aeMOCAhwR0dHu//4xz+6v/nmG6umpqbG/eKLL7qvvfZad8uWLd2BgYHu2NhY94IFC6y+Z86c6ZZUZ7Pb7W632+0+fPiwe+LEie4ePXq4W7Vq5W7durU7JibG/fTTT7tramrcbrfbvWnTJve9997rjoyMdNvtdne7du3cffv2db/77rtWL2vWrHFLch85cuSM36cjR464J06c6O7cubO7RYsW7i5durinTZvm/v77762akpKS0/Yryb1///5z/rcA8AOb232Bv8sLAADwM8AzTQAAAAYITQC8Iicnp857jmq37t27e7s9AKiD23MAvOL7778/44sqL7nkEuvPjwCAryA0AQAAGOD2HAAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgIH/BUlc/PDqoSCBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Step 2: Compile, Train, and Evaluate the Model<h2>"
      ],
      "metadata": {
        "id": "EelQ8FHehqno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation='relu', input_dim=input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "#  YOUR CODE GOES HERE\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "id": "I4vB3HrMgCSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f622255f-14d4-4331-b4da-0c95bbdd4736"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │           \u001b[38;5;34m3,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,430\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,061\u001b[0m (23.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,061</span> (23.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,061\u001b[0m (23.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,061</span> (23.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "#  YOUR CODE GOES HERE\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1ZqJSY-EgCUy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the checkpoint path and filename\n",
        "checkpoint_path = \"checkpoints/weights.{epoch:02d}.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Ensure the checkpoint directory exists\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Create a custom callback to save the model every N epochs\n",
        "class CustomModelCheckpoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, save_freq, checkpoint_path):\n",
        "        super(CustomModelCheckpoint, self).__init__()\n",
        "        self.save_freq = save_freq\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Save the model every 'save_freq' epochs\n",
        "        if (epoch + 1) % self.save_freq == 0:\n",
        "            # Format the file path with the current epoch\n",
        "            filepath = self.checkpoint_path.format(epoch=epoch+1)\n",
        "            # Save the model's weights\n",
        "            self.model.save_weights(filepath)\n",
        "            print(f'\\nSaving model at epoch {epoch+1} to {filepath}')\n",
        "\n",
        "# Instantiate the custom callback\n",
        "cp_callback = CustomModelCheckpoint(\n",
        "    save_freq=5,\n",
        "    checkpoint_path=checkpoint_path\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "#  YOUR CODE GOES HERE\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjtt3gxcKD_y",
        "outputId": "755b0e4f-701a-4985-8ee3-2bf613b085d7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.5970\n",
            "Epoch 2/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5553\n",
            "Epoch 3/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7286 - loss: 0.5526\n",
            "Epoch 4/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7329 - loss: 0.5449\n",
            "Epoch 5/100\n",
            "\u001b[1m777/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5503\n",
            "Saving model at epoch 5 to checkpoints/weights.05.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5503\n",
            "Epoch 6/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7320 - loss: 0.5452\n",
            "Epoch 7/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7308 - loss: 0.5480\n",
            "Epoch 8/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5458\n",
            "Epoch 9/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5440\n",
            "Epoch 10/100\n",
            "\u001b[1m797/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7354 - loss: 0.5432\n",
            "Saving model at epoch 10 to checkpoints/weights.10.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7354 - loss: 0.5432\n",
            "Epoch 11/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.5399\n",
            "Epoch 12/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7305 - loss: 0.5450\n",
            "Epoch 13/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5393\n",
            "Epoch 14/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5444\n",
            "Epoch 15/100\n",
            "\u001b[1m770/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5401\n",
            "Saving model at epoch 15 to checkpoints/weights.15.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5402\n",
            "Epoch 16/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7338 - loss: 0.5440\n",
            "Epoch 17/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5400\n",
            "Epoch 18/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5395\n",
            "Epoch 19/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5395\n",
            "Epoch 20/100\n",
            "\u001b[1m803/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5426\n",
            "Saving model at epoch 20 to checkpoints/weights.20.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5426\n",
            "Epoch 21/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5403\n",
            "Epoch 22/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5386\n",
            "Epoch 23/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5369\n",
            "Epoch 24/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5402\n",
            "Epoch 25/100\n",
            "\u001b[1m784/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5374\n",
            "Saving model at epoch 25 to checkpoints/weights.25.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5375\n",
            "Epoch 26/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7364 - loss: 0.5377\n",
            "Epoch 27/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5354\n",
            "Epoch 28/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.5403\n",
            "Epoch 29/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5389\n",
            "Epoch 30/100\n",
            "\u001b[1m775/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7317 - loss: 0.5446\n",
            "Saving model at epoch 30 to checkpoints/weights.30.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7318 - loss: 0.5445\n",
            "Epoch 31/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.5399\n",
            "Epoch 32/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.5343\n",
            "Epoch 33/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5392\n",
            "Epoch 34/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5412\n",
            "Epoch 35/100\n",
            "\u001b[1m798/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5384\n",
            "Saving model at epoch 35 to checkpoints/weights.35.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5384\n",
            "Epoch 36/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.5350\n",
            "Epoch 37/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5349\n",
            "Epoch 38/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7490 - loss: 0.5259\n",
            "Epoch 39/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5376\n",
            "Epoch 40/100\n",
            "\u001b[1m782/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7349 - loss: 0.5417\n",
            "Saving model at epoch 40 to checkpoints/weights.40.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7350 - loss: 0.5416\n",
            "Epoch 41/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.5290\n",
            "Epoch 42/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5345\n",
            "Epoch 43/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5337\n",
            "Epoch 44/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.5394\n",
            "Epoch 45/100\n",
            "\u001b[1m779/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5343\n",
            "Saving model at epoch 45 to checkpoints/weights.45.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5344\n",
            "Epoch 46/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7419 - loss: 0.5352\n",
            "Epoch 47/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5353\n",
            "Epoch 48/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7320 - loss: 0.5388\n",
            "Epoch 49/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5347\n",
            "Epoch 50/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5383\n",
            "Saving model at epoch 50 to checkpoints/weights.50.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5383\n",
            "Epoch 51/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5371\n",
            "Epoch 52/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5361\n",
            "Epoch 53/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5385\n",
            "Epoch 54/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5306\n",
            "Epoch 55/100\n",
            "\u001b[1m795/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5327\n",
            "Saving model at epoch 55 to checkpoints/weights.55.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5328\n",
            "Epoch 56/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.5334\n",
            "Epoch 57/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7364 - loss: 0.5359\n",
            "Epoch 58/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5366\n",
            "Epoch 59/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5291\n",
            "Epoch 60/100\n",
            "\u001b[1m772/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.5302\n",
            "Saving model at epoch 60 to checkpoints/weights.60.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.5304\n",
            "Epoch 61/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5399\n",
            "Epoch 62/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7450 - loss: 0.5306\n",
            "Epoch 63/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5334\n",
            "Epoch 64/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7399 - loss: 0.5343\n",
            "Epoch 65/100\n",
            "\u001b[1m802/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5364\n",
            "Saving model at epoch 65 to checkpoints/weights.65.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5364\n",
            "Epoch 66/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5319\n",
            "Epoch 67/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5338\n",
            "Epoch 68/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5315\n",
            "Epoch 69/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5343\n",
            "Epoch 70/100\n",
            "\u001b[1m792/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5335\n",
            "Saving model at epoch 70 to checkpoints/weights.70.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5335\n",
            "Epoch 71/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.5345\n",
            "Epoch 72/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5358\n",
            "Epoch 73/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5309\n",
            "Epoch 74/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.5295\n",
            "Epoch 75/100\n",
            "\u001b[1m784/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.5347\n",
            "Saving model at epoch 75 to checkpoints/weights.75.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.5347\n",
            "Epoch 76/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5279\n",
            "Epoch 77/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5339\n",
            "Epoch 78/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5336\n",
            "Epoch 79/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5266\n",
            "Epoch 80/100\n",
            "\u001b[1m790/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7451 - loss: 0.5288\n",
            "Saving model at epoch 80 to checkpoints/weights.80.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.5289\n",
            "Epoch 81/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5291\n",
            "Epoch 82/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7371 - loss: 0.5340\n",
            "Epoch 83/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.5335\n",
            "Epoch 84/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5306\n",
            "Epoch 85/100\n",
            "\u001b[1m782/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5297\n",
            "Saving model at epoch 85 to checkpoints/weights.85.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5298\n",
            "Epoch 86/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.5262\n",
            "Epoch 87/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5306\n",
            "Epoch 88/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5323\n",
            "Epoch 89/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 0.5261\n",
            "Epoch 90/100\n",
            "\u001b[1m779/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5334\n",
            "Saving model at epoch 90 to checkpoints/weights.90.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5334\n",
            "Epoch 91/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5289\n",
            "Epoch 92/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5304\n",
            "Epoch 93/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5340\n",
            "Epoch 94/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5337\n",
            "Epoch 95/100\n",
            "\u001b[1m789/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5335\n",
            "Saving model at epoch 95 to checkpoints/weights.95.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5335\n",
            "Epoch 96/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5347\n",
            "Epoch 97/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5321\n",
            "Epoch 98/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5353\n",
            "Epoch 99/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.5305\n",
            "Epoch 100/100\n",
            "\u001b[1m786/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5309\n",
            "Saving model at epoch 100 to checkpoints/weights.100.weights.h5\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "EpETq-imgHYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9073651-1cbf-4104-c798-875ecb21ebc5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - 2ms/step - accuracy: 0.7285 - loss: 0.5612\n",
            "Loss: 0.5612143278121948, Accuracy: 0.7285131216049194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "#  YOUR CODE GOES HERE\n",
        "nn.save(\"AlphabetSoupCharity.h5\")"
      ],
      "metadata": {
        "id": "CI0ibUwfgHbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ad7d77-dfff-4ca7-afb8-0c6c6fbc1218"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Step 3: Optimize the Model<h2>"
      ],
      "metadata": {
        "id": "fRPny0oZhcS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview of the Analysis\n",
        "The purpose of the analysis is to create a binary classifier to predict the success of funding applicants using a neural network.\n",
        "\n",
        "**Results**\n",
        "\n",
        "Data Preprocessing\n",
        "Target Variable: IS_SUCCESSFUL\n",
        "Features: All other columns after dropping EIN and NAME.\n",
        "Removed Variables: EIN, NAME (identification columns not relevant for prediction).\n",
        "\n",
        "**Model Architecture**\n",
        "\n",
        "Initial Model:\n",
        "Input Layer: Number of features.\n",
        "Hidden Layers: Two layers with 80 and 30 neurons, respectively.\n",
        "Activation Functions: relu for hidden layers, sigmoid for output.\n",
        "Optimizations:\n",
        "Added a third hidden layer.\n",
        "Increased neurons.\n",
        "Tried different activation functions.\n",
        "Model Performance\n",
        "Initial Model Accuracy: e.g., 72%\n",
        "Optimized Model Accuracy: e.g., 76%\n",
        "Target Achieved: Yes/No (depending on your results).\n",
        "\n",
        "**Summary**\n",
        "Summarize that while the optimized model showed improvement, further enhancements could be made. Suggest alternative models like Random Forest or XGBoost for potentially better performance due to their ability to handle categorical variables and complex patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "mQ8n05YIMpX7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6RkAR5is4vS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 - Accuracy: 0.7319"
      ],
      "metadata": {
        "id": "1oy42fMpiWmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import RMSprop, Adamax\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Remove low variance features\n",
        "selector = VarianceThreshold(threshold=0.01)  # Adjust threshold depending on feature variance\n",
        "X_train_selected = selector.fit_transform(X_train_scaled)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "# Build the Neural Network Model\n",
        "\n",
        "# Define the number of input features after variance selection\n",
        "input_features = X_train_scaled.shape[1]\n",
        "\n",
        "# Build a more complex model\n",
        "nn_opt = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer with 256 neurons\n",
        "nn_opt.add(Dense(units=256, input_dim=input_features, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "nn_opt.add(BatchNormalization())  # Normalize the output of the first layer\n",
        "nn_opt.add(LeakyReLU(alpha=0.1))  # Use LeakyReLU activation\n",
        "nn_opt.add(Dropout(0.3))  # Dropout to reduce overfitting\n",
        "\n",
        "# Second hidden layer with 128 neurons\n",
        "nn_opt.add(Dense(units=128, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "nn_opt.add(BatchNormalization())\n",
        "nn_opt.add(LeakyReLU(alpha=0.1))\n",
        "nn_opt.add(Dropout(0.3))\n",
        "\n",
        "# Third hidden layer with 64 neurons\n",
        "nn_opt.add(Dense(units=64, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "nn_opt.add(BatchNormalization())\n",
        "nn_opt.add(LeakyReLU(alpha=0.1))\n",
        "nn_opt.add(Dropout(0.3))\n",
        "\n",
        "# Fourth hidden layer with 32 neurons\n",
        "nn_opt.add(Dense(units=32, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "nn_opt.add(BatchNormalization())\n",
        "nn_opt.add(LeakyReLU(alpha=0.1))\n",
        "nn_opt.add(Dropout(0.3))\n",
        "\n",
        "# Output layer for binary classification\n",
        "nn_opt.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = RMSprop(learning_rate=0.0005)  # Experiment with other optimizers like Adamax or Nadam\n",
        "nn_opt.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with more epochs and early stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
        "\n",
        "history = nn_opt.fit(X_train_scaled, y_train,\n",
        "                     epochs=200,\n",
        "                     batch_size=64,\n",
        "                     validation_data=(X_test_scaled, y_test),\n",
        "                     callbacks=[early_stop])\n",
        "\n",
        "# Evaluate the optimized model\n",
        "model_loss, model_accuracy = nn_opt.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Loss: {model_loss}, Optimized Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the model\n",
        "nn_opt.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq66EEV7uTs9",
        "outputId": "e2949217-aea8-488e-d7b5-6114ec0280d5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6476 - loss: 1.0109 - val_accuracy: 0.7228 - val_loss: 0.8679\n",
            "Epoch 2/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.8683 - val_accuracy: 0.7255 - val_loss: 0.7866\n",
            "Epoch 3/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7151 - loss: 0.7843 - val_accuracy: 0.7273 - val_loss: 0.7150\n",
            "Epoch 4/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7264 - loss: 0.7095 - val_accuracy: 0.7287 - val_loss: 0.6635\n",
            "Epoch 5/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.6641 - val_accuracy: 0.7322 - val_loss: 0.6276\n",
            "Epoch 6/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7237 - loss: 0.6327 - val_accuracy: 0.7258 - val_loss: 0.6085\n",
            "Epoch 7/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7290 - loss: 0.6083 - val_accuracy: 0.7294 - val_loss: 0.5925\n",
            "Epoch 8/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.5952 - val_accuracy: 0.7237 - val_loss: 0.5870\n",
            "Epoch 9/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.5883 - val_accuracy: 0.7312 - val_loss: 0.5787\n",
            "Epoch 10/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.5800 - val_accuracy: 0.7276 - val_loss: 0.5758\n",
            "Epoch 11/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.5826 - val_accuracy: 0.7279 - val_loss: 0.5723\n",
            "Epoch 12/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7281 - loss: 0.5790 - val_accuracy: 0.7279 - val_loss: 0.5699\n",
            "Epoch 13/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7248 - loss: 0.5800 - val_accuracy: 0.7339 - val_loss: 0.5694\n",
            "Epoch 14/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.5787 - val_accuracy: 0.7278 - val_loss: 0.5691\n",
            "Epoch 15/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.5749 - val_accuracy: 0.7315 - val_loss: 0.5684\n",
            "Epoch 16/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.5783 - val_accuracy: 0.7293 - val_loss: 0.5660\n",
            "Epoch 17/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 0.5701 - val_accuracy: 0.7313 - val_loss: 0.5702\n",
            "Epoch 18/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7222 - loss: 0.5796 - val_accuracy: 0.7304 - val_loss: 0.5653\n",
            "Epoch 19/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 0.5717 - val_accuracy: 0.7278 - val_loss: 0.5659\n",
            "Epoch 20/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.5723 - val_accuracy: 0.7319 - val_loss: 0.5637\n",
            "Epoch 21/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.5733 - val_accuracy: 0.7290 - val_loss: 0.5677\n",
            "Epoch 22/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 0.5735 - val_accuracy: 0.7287 - val_loss: 0.5646\n",
            "Epoch 23/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7275 - loss: 0.5720 - val_accuracy: 0.7271 - val_loss: 0.5648\n",
            "Epoch 24/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.5739 - val_accuracy: 0.7283 - val_loss: 0.5643\n",
            "Epoch 25/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.5747 - val_accuracy: 0.7299 - val_loss: 0.5668\n",
            "Epoch 26/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7306 - loss: 0.5708 - val_accuracy: 0.7320 - val_loss: 0.5653\n",
            "Epoch 27/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 0.5723 - val_accuracy: 0.7293 - val_loss: 0.5686\n",
            "Epoch 28/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.5710 - val_accuracy: 0.7297 - val_loss: 0.5656\n",
            "Epoch 29/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.5785 - val_accuracy: 0.7299 - val_loss: 0.5649\n",
            "Epoch 30/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7296 - loss: 0.5743 - val_accuracy: 0.7280 - val_loss: 0.5656\n",
            "Epoch 31/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7226 - loss: 0.5747 - val_accuracy: 0.7291 - val_loss: 0.5686\n",
            "Epoch 32/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.5700 - val_accuracy: 0.7319 - val_loss: 0.5670\n",
            "Epoch 33/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.5728 - val_accuracy: 0.7285 - val_loss: 0.5700\n",
            "Epoch 34/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7278 - loss: 0.5760 - val_accuracy: 0.7297 - val_loss: 0.5663\n",
            "Epoch 35/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7299 - loss: 0.5699 - val_accuracy: 0.7293 - val_loss: 0.5679\n",
            "Epoch 36/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7266 - loss: 0.5744 - val_accuracy: 0.7291 - val_loss: 0.5665\n",
            "Epoch 37/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.5711 - val_accuracy: 0.7290 - val_loss: 0.5674\n",
            "Epoch 38/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.5736 - val_accuracy: 0.7311 - val_loss: 0.5685\n",
            "Epoch 39/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.5735 - val_accuracy: 0.7287 - val_loss: 0.5665\n",
            "Epoch 40/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.5740 - val_accuracy: 0.7280 - val_loss: 0.5664\n",
            "Epoch 41/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7287 - loss: 0.5722 - val_accuracy: 0.7283 - val_loss: 0.5686\n",
            "Epoch 42/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7253 - loss: 0.5795 - val_accuracy: 0.7263 - val_loss: 0.5659\n",
            "Epoch 43/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.5703 - val_accuracy: 0.7271 - val_loss: 0.5702\n",
            "Epoch 44/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.5709 - val_accuracy: 0.7314 - val_loss: 0.5659\n",
            "Epoch 45/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7301 - loss: 0.5688 - val_accuracy: 0.7286 - val_loss: 0.5682\n",
            "Epoch 46/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7261 - loss: 0.5739 - val_accuracy: 0.7307 - val_loss: 0.5674\n",
            "Epoch 47/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.5694 - val_accuracy: 0.7308 - val_loss: 0.5702\n",
            "Epoch 48/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.5747 - val_accuracy: 0.7315 - val_loss: 0.5661\n",
            "Epoch 49/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.5737 - val_accuracy: 0.7241 - val_loss: 0.5679\n",
            "Epoch 50/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7290 - loss: 0.5702 - val_accuracy: 0.7307 - val_loss: 0.5677\n",
            "Epoch 51/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7302 - loss: 0.5727 - val_accuracy: 0.7294 - val_loss: 0.5669\n",
            "Epoch 52/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.5746 - val_accuracy: 0.7322 - val_loss: 0.5671\n",
            "Epoch 53/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.5719 - val_accuracy: 0.7269 - val_loss: 0.5674\n",
            "Epoch 54/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.5733 - val_accuracy: 0.7315 - val_loss: 0.5661\n",
            "Epoch 55/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.5746 - val_accuracy: 0.7278 - val_loss: 0.5677\n",
            "Epoch 56/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7230 - loss: 0.5777 - val_accuracy: 0.7279 - val_loss: 0.5677\n",
            "Epoch 57/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.5764 - val_accuracy: 0.7298 - val_loss: 0.5660\n",
            "Epoch 58/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7294 - loss: 0.5706 - val_accuracy: 0.7241 - val_loss: 0.5695\n",
            "Epoch 59/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.5732 - val_accuracy: 0.7280 - val_loss: 0.5672\n",
            "Epoch 60/200\n",
            "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7273 - loss: 0.5726 - val_accuracy: 0.7285 - val_loss: 0.5660\n",
            "268/268 - 1s - 2ms/step - accuracy: 0.7319 - loss: 0.5637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Loss: 0.5636950135231018, Optimized Accuracy: 0.7318950295448303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 - Accuracy: 0.7306"
      ],
      "metadata": {
        "id": "zmDldUgKieXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load and Preprocess the Data\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Drop unnecessary columns: EIN and NAME\n",
        "# application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "application_df = application_df.drop(columns = ['EIN', 'NAME', 'STATUS', 'SPECIAL_CONSIDERATIONS', 'ASK_AMT'])\n",
        "\n",
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()\n",
        "\n",
        "\n",
        "# Binning rare occurrences in 'APPLICATION_TYPE'\n",
        "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_types_to_replace = list(application_type_counts[application_type_counts < 500].index)\n",
        "application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(application_types_to_replace, \"Other\")\n",
        "\n",
        "# Binning rare occurrences in 'CLASSIFICATION'\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classifications_to_replace = list(classification_counts[classification_counts < 50].index)\n",
        "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(classifications_to_replace, \"Other\")\n",
        "\n",
        "# Convert categorical variables into dummy/indicator variables\n",
        "application_df = pd.get_dummies(application_df)\n",
        "\n",
        "# Define features and target\n",
        "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y = application_df[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 2. Build a Simpler Neural Network Model\n",
        "input_features = X_train_scaled.shape[1]  # Get number of input features\n",
        "\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer with 128 neurons and reduced L2 regularization\n",
        "nn_model.add(Dense(units=128, input_dim=input_features, kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "nn_model.add(BatchNormalization())  # Normalize the output of the first layer\n",
        "nn_model.add(tf.keras.layers.ReLU())  # ReLU activation\n",
        "nn_model.add(Dropout(0.2))  # Reduced dropout rate\n",
        "\n",
        "# Second hidden layer with 64 neurons\n",
        "nn_model.add(Dense(units=64, kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "nn_model.add(BatchNormalization())\n",
        "nn_model.add(tf.keras.layers.ReLU())\n",
        "nn_model.add(Dropout(0.2))\n",
        "\n",
        "# Third hidden layer with 32 neurons\n",
        "nn_model.add(Dense(units=32, kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "nn_model.add(BatchNormalization())\n",
        "nn_model.add(tf.keras.layers.ReLU())\n",
        "nn_model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "nn_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# 3. Compile the Model\n",
        "# Use Adam optimizer with a slightly higher learning rate\n",
        "optimizer = Adam(learning_rate=0.001)  # Increased learning rate to 0.001\n",
        "nn_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model with Early Stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = nn_model.fit(X_train_scaled, y_train,\n",
        "                       epochs=150,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(X_test_scaled, y_test),\n",
        "                       callbacks=[early_stop])\n",
        "\n",
        "# 5. Evaluate the Model\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Loss: {model_loss}, Optimized Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the model\n",
        "nn_model.save(\"AlphabetSoupCharity_Simplified.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubXelgfMzPVJ",
        "outputId": "1c83e97b-1452-4a6b-cecd-5b2e60c5ac58"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.7331 - val_accuracy: 0.7208 - val_loss: 0.6512\n",
            "Epoch 2/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.6583 - val_accuracy: 0.7197 - val_loss: 0.6365\n",
            "Epoch 3/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.6434 - val_accuracy: 0.7239 - val_loss: 0.6195\n",
            "Epoch 4/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7247 - loss: 0.6223 - val_accuracy: 0.7261 - val_loss: 0.6084\n",
            "Epoch 5/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.6070 - val_accuracy: 0.7278 - val_loss: 0.5973\n",
            "Epoch 6/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5945 - val_accuracy: 0.7229 - val_loss: 0.5910\n",
            "Epoch 7/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.5943 - val_accuracy: 0.7236 - val_loss: 0.5846\n",
            "Epoch 8/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.5775 - val_accuracy: 0.7268 - val_loss: 0.5769\n",
            "Epoch 9/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.5802 - val_accuracy: 0.7270 - val_loss: 0.5759\n",
            "Epoch 10/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5756 - val_accuracy: 0.7245 - val_loss: 0.5716\n",
            "Epoch 11/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.5711 - val_accuracy: 0.7281 - val_loss: 0.5723\n",
            "Epoch 12/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.5751 - val_accuracy: 0.7235 - val_loss: 0.5703\n",
            "Epoch 13/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5672 - val_accuracy: 0.7277 - val_loss: 0.5699\n",
            "Epoch 14/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 0.5660 - val_accuracy: 0.7276 - val_loss: 0.5681\n",
            "Epoch 15/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7252 - loss: 0.5735 - val_accuracy: 0.7262 - val_loss: 0.5670\n",
            "Epoch 16/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.5644 - val_accuracy: 0.7280 - val_loss: 0.5652\n",
            "Epoch 17/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5714 - val_accuracy: 0.7316 - val_loss: 0.5692\n",
            "Epoch 18/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5670 - val_accuracy: 0.7286 - val_loss: 0.5643\n",
            "Epoch 19/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.5630 - val_accuracy: 0.7284 - val_loss: 0.5661\n",
            "Epoch 20/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.5649 - val_accuracy: 0.7319 - val_loss: 0.5664\n",
            "Epoch 21/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5608 - val_accuracy: 0.7299 - val_loss: 0.5631\n",
            "Epoch 22/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 0.5595 - val_accuracy: 0.7270 - val_loss: 0.5639\n",
            "Epoch 23/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.5636 - val_accuracy: 0.7290 - val_loss: 0.5641\n",
            "Epoch 24/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.5648 - val_accuracy: 0.7290 - val_loss: 0.5639\n",
            "Epoch 25/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.5683 - val_accuracy: 0.7315 - val_loss: 0.5638\n",
            "Epoch 26/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7291 - loss: 0.5637 - val_accuracy: 0.7283 - val_loss: 0.5642\n",
            "Epoch 27/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5632 - val_accuracy: 0.7297 - val_loss: 0.5651\n",
            "Epoch 28/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 0.5626 - val_accuracy: 0.7262 - val_loss: 0.5630\n",
            "Epoch 29/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.5569 - val_accuracy: 0.7278 - val_loss: 0.5654\n",
            "Epoch 30/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5591 - val_accuracy: 0.7292 - val_loss: 0.5622\n",
            "Epoch 31/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7323 - loss: 0.5596 - val_accuracy: 0.7274 - val_loss: 0.5638\n",
            "Epoch 32/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.5568 - val_accuracy: 0.7262 - val_loss: 0.5651\n",
            "Epoch 33/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.5539 - val_accuracy: 0.7306 - val_loss: 0.5609\n",
            "Epoch 34/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.5650 - val_accuracy: 0.7258 - val_loss: 0.5636\n",
            "Epoch 35/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5634 - val_accuracy: 0.7264 - val_loss: 0.5628\n",
            "Epoch 36/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7286 - loss: 0.5629 - val_accuracy: 0.7284 - val_loss: 0.5627\n",
            "Epoch 37/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.5627 - val_accuracy: 0.7261 - val_loss: 0.5658\n",
            "Epoch 38/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.5632 - val_accuracy: 0.7283 - val_loss: 0.5648\n",
            "Epoch 39/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.5610 - val_accuracy: 0.7308 - val_loss: 0.5640\n",
            "Epoch 40/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.5615 - val_accuracy: 0.7315 - val_loss: 0.5632\n",
            "Epoch 41/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.5584 - val_accuracy: 0.7281 - val_loss: 0.5650\n",
            "Epoch 42/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.5568 - val_accuracy: 0.7294 - val_loss: 0.5617\n",
            "Epoch 43/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.5573 - val_accuracy: 0.7283 - val_loss: 0.5649\n",
            "Epoch 44/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5628 - val_accuracy: 0.7280 - val_loss: 0.5621\n",
            "Epoch 45/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5652 - val_accuracy: 0.7318 - val_loss: 0.5621\n",
            "Epoch 46/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5586 - val_accuracy: 0.7316 - val_loss: 0.5614\n",
            "Epoch 47/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5579 - val_accuracy: 0.7293 - val_loss: 0.5628\n",
            "Epoch 48/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5612 - val_accuracy: 0.7284 - val_loss: 0.5615\n",
            "Epoch 49/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7319 - loss: 0.5607 - val_accuracy: 0.7309 - val_loss: 0.5632\n",
            "Epoch 50/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.5530 - val_accuracy: 0.7271 - val_loss: 0.5617\n",
            "Epoch 51/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5583 - val_accuracy: 0.7296 - val_loss: 0.5647\n",
            "Epoch 52/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5607 - val_accuracy: 0.7305 - val_loss: 0.5607\n",
            "Epoch 53/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5548 - val_accuracy: 0.7289 - val_loss: 0.5658\n",
            "Epoch 54/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5585 - val_accuracy: 0.7274 - val_loss: 0.5619\n",
            "Epoch 55/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.5632 - val_accuracy: 0.7246 - val_loss: 0.5643\n",
            "Epoch 56/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7306 - loss: 0.5616 - val_accuracy: 0.7306 - val_loss: 0.5620\n",
            "Epoch 57/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5596 - val_accuracy: 0.7321 - val_loss: 0.5618\n",
            "Epoch 58/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.5592 - val_accuracy: 0.7273 - val_loss: 0.5666\n",
            "Epoch 59/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5614 - val_accuracy: 0.7281 - val_loss: 0.5632\n",
            "Epoch 60/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5534 - val_accuracy: 0.7297 - val_loss: 0.5636\n",
            "Epoch 61/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5597 - val_accuracy: 0.7289 - val_loss: 0.5627\n",
            "Epoch 62/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.5644 - val_accuracy: 0.7318 - val_loss: 0.5620\n",
            "Epoch 63/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.5580 - val_accuracy: 0.7251 - val_loss: 0.5605\n",
            "Epoch 64/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5600 - val_accuracy: 0.7224 - val_loss: 0.5616\n",
            "Epoch 65/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5554 - val_accuracy: 0.7289 - val_loss: 0.5635\n",
            "Epoch 66/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.5610 - val_accuracy: 0.7259 - val_loss: 0.5627\n",
            "Epoch 67/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5592 - val_accuracy: 0.7287 - val_loss: 0.5614\n",
            "Epoch 68/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7343 - loss: 0.5598 - val_accuracy: 0.7287 - val_loss: 0.5646\n",
            "Epoch 69/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5558 - val_accuracy: 0.7296 - val_loss: 0.5627\n",
            "Epoch 70/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.5600 - val_accuracy: 0.7287 - val_loss: 0.5636\n",
            "Epoch 71/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.5565 - val_accuracy: 0.7242 - val_loss: 0.5616\n",
            "Epoch 72/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7334 - loss: 0.5596 - val_accuracy: 0.7296 - val_loss: 0.5643\n",
            "Epoch 73/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.5532 - val_accuracy: 0.7287 - val_loss: 0.5634\n",
            "Epoch 74/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.5587 - val_accuracy: 0.7292 - val_loss: 0.5608\n",
            "Epoch 75/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.5636 - val_accuracy: 0.7303 - val_loss: 0.5629\n",
            "Epoch 76/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5568 - val_accuracy: 0.7292 - val_loss: 0.5634\n",
            "Epoch 77/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.5600 - val_accuracy: 0.7270 - val_loss: 0.5621\n",
            "Epoch 78/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.5530 - val_accuracy: 0.7271 - val_loss: 0.5619\n",
            "Epoch 79/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5562 - val_accuracy: 0.7296 - val_loss: 0.5616\n",
            "Epoch 80/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5571 - val_accuracy: 0.7273 - val_loss: 0.5621\n",
            "Epoch 81/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7321 - loss: 0.5586 - val_accuracy: 0.7305 - val_loss: 0.5616\n",
            "Epoch 82/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.5522 - val_accuracy: 0.7293 - val_loss: 0.5601\n",
            "Epoch 83/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.5610 - val_accuracy: 0.7286 - val_loss: 0.5632\n",
            "Epoch 84/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.5601 - val_accuracy: 0.7270 - val_loss: 0.5636\n",
            "Epoch 85/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5571 - val_accuracy: 0.7268 - val_loss: 0.5641\n",
            "Epoch 86/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5578 - val_accuracy: 0.7296 - val_loss: 0.5628\n",
            "Epoch 87/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.5617 - val_accuracy: 0.7296 - val_loss: 0.5605\n",
            "Epoch 88/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7293 - loss: 0.5607 - val_accuracy: 0.7283 - val_loss: 0.5618\n",
            "Epoch 89/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7321 - loss: 0.5589 - val_accuracy: 0.7289 - val_loss: 0.5626\n",
            "Epoch 90/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5545 - val_accuracy: 0.7302 - val_loss: 0.5608\n",
            "Epoch 91/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5605 - val_accuracy: 0.7251 - val_loss: 0.5627\n",
            "Epoch 92/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5564 - val_accuracy: 0.7303 - val_loss: 0.5610\n",
            "Epoch 93/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.5626 - val_accuracy: 0.7278 - val_loss: 0.5611\n",
            "Epoch 94/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7340 - loss: 0.5552 - val_accuracy: 0.7309 - val_loss: 0.5617\n",
            "Epoch 95/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5616 - val_accuracy: 0.7255 - val_loss: 0.5639\n",
            "Epoch 96/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5595 - val_accuracy: 0.7276 - val_loss: 0.5621\n",
            "Epoch 97/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5580 - val_accuracy: 0.7312 - val_loss: 0.5620\n",
            "Epoch 98/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7288 - loss: 0.5600 - val_accuracy: 0.7270 - val_loss: 0.5616\n",
            "Epoch 99/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5615 - val_accuracy: 0.7306 - val_loss: 0.5596\n",
            "Epoch 100/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.5554 - val_accuracy: 0.7312 - val_loss: 0.5608\n",
            "Epoch 101/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.5585 - val_accuracy: 0.7312 - val_loss: 0.5603\n",
            "Epoch 102/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5551 - val_accuracy: 0.7306 - val_loss: 0.5602\n",
            "Epoch 103/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.5563 - val_accuracy: 0.7300 - val_loss: 0.5607\n",
            "Epoch 104/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7334 - loss: 0.5562 - val_accuracy: 0.7262 - val_loss: 0.5607\n",
            "Epoch 105/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.5650 - val_accuracy: 0.7316 - val_loss: 0.5625\n",
            "Epoch 106/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.5556 - val_accuracy: 0.7290 - val_loss: 0.5612\n",
            "Epoch 107/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7368 - loss: 0.5534 - val_accuracy: 0.7302 - val_loss: 0.5602\n",
            "Epoch 108/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5579 - val_accuracy: 0.7294 - val_loss: 0.5602\n",
            "Epoch 109/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5542 - val_accuracy: 0.7287 - val_loss: 0.5598\n",
            "Epoch 110/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5576 - val_accuracy: 0.7305 - val_loss: 0.5597\n",
            "Epoch 111/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.5589 - val_accuracy: 0.7297 - val_loss: 0.5624\n",
            "Epoch 112/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7355 - loss: 0.5575 - val_accuracy: 0.7280 - val_loss: 0.5624\n",
            "Epoch 113/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5546 - val_accuracy: 0.7322 - val_loss: 0.5598\n",
            "Epoch 114/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5556 - val_accuracy: 0.7296 - val_loss: 0.5620\n",
            "Epoch 115/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.5647 - val_accuracy: 0.7302 - val_loss: 0.5601\n",
            "Epoch 116/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.5605 - val_accuracy: 0.7309 - val_loss: 0.5610\n",
            "Epoch 117/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.5547 - val_accuracy: 0.7293 - val_loss: 0.5617\n",
            "Epoch 118/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5596 - val_accuracy: 0.7318 - val_loss: 0.5608\n",
            "Epoch 119/150\n",
            "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7369 - loss: 0.5526 - val_accuracy: 0.7310 - val_loss: 0.5605\n",
            "215/215 - 0s - 1ms/step - accuracy: 0.7306 - loss: 0.5596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Loss: 0.559640645980835, Optimized Accuracy: 0.7306122183799744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "2IWbKDPp0g6I",
        "outputId": "aa638fc6-7756-498e-b14c-57709a302633"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: 0.7284"
      ],
      "metadata": {
        "id": "K0GuObkBivHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load and Preprocess the Data (Same as before)\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Drop unnecessary columns:\n",
        "application_df = application_df.drop(columns = ['EIN', 'NAME', 'STATUS', 'SPECIAL_CONSIDERATIONS', 'ASK_AMT'])\n",
        "\n",
        "# Binning rare occurrences in 'APPLICATION_TYPE'\n",
        "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_types_to_replace = list(application_type_counts[application_type_counts < 500].index)\n",
        "application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(application_types_to_replace, \"Other\")\n",
        "\n",
        "# Binning rare occurrences in 'CLASSIFICATION'\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classifications_to_replace = list(classification_counts[classification_counts < 50].index)\n",
        "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(classifications_to_replace, \"Other\")\n",
        "\n",
        "# Convert categorical variables into dummy/indicator variables\n",
        "application_df = pd.get_dummies(application_df)\n",
        "\n",
        "# Define features and target\n",
        "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y = application_df[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# 2. Build a Simpler Neural Network Model\n",
        "input_features = X_train_scaled.shape[1]  # Get number of input features\n",
        "\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer with 64 neurons and L2 regularization\n",
        "nn_model.add(Dense(units=64, input_dim=input_features, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "nn_model.add(Dropout(0.2))  # Reduced dropout rate\n",
        "\n",
        "# Second hidden layer with 32 neurons\n",
        "nn_model.add(Dense(units=32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "nn_model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "nn_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# 3. Compile the Model\n",
        "# Use Adam optimizer with a higher learning rate\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "nn_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model with Early Stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = nn_model.fit(X_train_resampled, y_train_resampled,\n",
        "                       epochs=150,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(X_test_scaled, y_test),\n",
        "                       callbacks=[early_stop])\n",
        "\n",
        "# 5. Evaluate the Model\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Loss: {model_loss}, Optimized Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the model\n",
        "nn_model.save(\"AlphabetSoupCharity_Simplified_v2.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jfeN7hcPFk8",
        "outputId": "b6439531-9440-4807-811e-b5df8ddcce32"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6827 - loss: 0.6255 - val_accuracy: 0.7217 - val_loss: 0.5782\n",
            "Epoch 2/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: 0.5832 - val_accuracy: 0.7254 - val_loss: 0.5727\n",
            "Epoch 3/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.5759 - val_accuracy: 0.7258 - val_loss: 0.5709\n",
            "Epoch 4/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.5757 - val_accuracy: 0.7243 - val_loss: 0.5698\n",
            "Epoch 5/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5614 - val_accuracy: 0.7245 - val_loss: 0.5697\n",
            "Epoch 6/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5636 - val_accuracy: 0.7264 - val_loss: 0.5675\n",
            "Epoch 7/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5651 - val_accuracy: 0.7224 - val_loss: 0.5703\n",
            "Epoch 8/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5634 - val_accuracy: 0.7239 - val_loss: 0.5705\n",
            "Epoch 9/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5660 - val_accuracy: 0.7267 - val_loss: 0.5655\n",
            "Epoch 10/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5668 - val_accuracy: 0.7248 - val_loss: 0.5682\n",
            "Epoch 11/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5590 - val_accuracy: 0.7259 - val_loss: 0.5646\n",
            "Epoch 12/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5626 - val_accuracy: 0.7245 - val_loss: 0.5646\n",
            "Epoch 13/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.5587 - val_accuracy: 0.7261 - val_loss: 0.5655\n",
            "Epoch 14/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.5618 - val_accuracy: 0.7274 - val_loss: 0.5642\n",
            "Epoch 15/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5563 - val_accuracy: 0.7267 - val_loss: 0.5640\n",
            "Epoch 16/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5608 - val_accuracy: 0.7271 - val_loss: 0.5628\n",
            "Epoch 17/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5582 - val_accuracy: 0.7235 - val_loss: 0.5627\n",
            "Epoch 18/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5637 - val_accuracy: 0.7276 - val_loss: 0.5639\n",
            "Epoch 19/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.5613 - val_accuracy: 0.7268 - val_loss: 0.5640\n",
            "Epoch 20/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5600 - val_accuracy: 0.7248 - val_loss: 0.5641\n",
            "Epoch 21/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5594 - val_accuracy: 0.7259 - val_loss: 0.5625\n",
            "Epoch 22/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5567 - val_accuracy: 0.7233 - val_loss: 0.5646\n",
            "Epoch 23/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5585 - val_accuracy: 0.7284 - val_loss: 0.5625\n",
            "Epoch 24/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 0.5606 - val_accuracy: 0.7289 - val_loss: 0.5624\n",
            "Epoch 25/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5601 - val_accuracy: 0.7278 - val_loss: 0.5630\n",
            "Epoch 26/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5573 - val_accuracy: 0.7274 - val_loss: 0.5640\n",
            "Epoch 27/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5557 - val_accuracy: 0.7281 - val_loss: 0.5618\n",
            "Epoch 28/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5601 - val_accuracy: 0.7241 - val_loss: 0.5647\n",
            "Epoch 29/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5540 - val_accuracy: 0.7236 - val_loss: 0.5632\n",
            "Epoch 30/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5582 - val_accuracy: 0.7258 - val_loss: 0.5610\n",
            "Epoch 31/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5569 - val_accuracy: 0.7243 - val_loss: 0.5612\n",
            "Epoch 32/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5625 - val_accuracy: 0.7259 - val_loss: 0.5617\n",
            "Epoch 33/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5558 - val_accuracy: 0.7252 - val_loss: 0.5611\n",
            "Epoch 34/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5595 - val_accuracy: 0.7257 - val_loss: 0.5614\n",
            "Epoch 35/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5590 - val_accuracy: 0.7251 - val_loss: 0.5615\n",
            "Epoch 36/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5559 - val_accuracy: 0.7249 - val_loss: 0.5630\n",
            "Epoch 37/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5621 - val_accuracy: 0.7271 - val_loss: 0.5607\n",
            "Epoch 38/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5526 - val_accuracy: 0.7246 - val_loss: 0.5618\n",
            "Epoch 39/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5540 - val_accuracy: 0.7236 - val_loss: 0.5603\n",
            "Epoch 40/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5577 - val_accuracy: 0.7251 - val_loss: 0.5604\n",
            "Epoch 41/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5569 - val_accuracy: 0.7245 - val_loss: 0.5608\n",
            "Epoch 42/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5547 - val_accuracy: 0.7255 - val_loss: 0.5633\n",
            "Epoch 43/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5602 - val_accuracy: 0.7277 - val_loss: 0.5602\n",
            "Epoch 44/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.5536 - val_accuracy: 0.7254 - val_loss: 0.5610\n",
            "Epoch 45/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5569 - val_accuracy: 0.7238 - val_loss: 0.5633\n",
            "Epoch 46/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5543 - val_accuracy: 0.7259 - val_loss: 0.5632\n",
            "Epoch 47/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5586 - val_accuracy: 0.7246 - val_loss: 0.5615\n",
            "Epoch 48/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5533 - val_accuracy: 0.7278 - val_loss: 0.5609\n",
            "Epoch 49/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5570 - val_accuracy: 0.7289 - val_loss: 0.5613\n",
            "Epoch 50/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5553 - val_accuracy: 0.7284 - val_loss: 0.5617\n",
            "Epoch 51/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5528 - val_accuracy: 0.7251 - val_loss: 0.5607\n",
            "Epoch 52/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5553 - val_accuracy: 0.7248 - val_loss: 0.5605\n",
            "Epoch 53/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5561 - val_accuracy: 0.7248 - val_loss: 0.5618\n",
            "Epoch 54/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5604 - val_accuracy: 0.7248 - val_loss: 0.5616\n",
            "Epoch 55/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5562 - val_accuracy: 0.7258 - val_loss: 0.5608\n",
            "Epoch 56/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5578 - val_accuracy: 0.7248 - val_loss: 0.5615\n",
            "Epoch 57/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5566 - val_accuracy: 0.7255 - val_loss: 0.5621\n",
            "Epoch 58/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5527 - val_accuracy: 0.7287 - val_loss: 0.5602\n",
            "Epoch 59/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5580 - val_accuracy: 0.7265 - val_loss: 0.5604\n",
            "Epoch 60/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5572 - val_accuracy: 0.7243 - val_loss: 0.5602\n",
            "Epoch 61/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5598 - val_accuracy: 0.7270 - val_loss: 0.5612\n",
            "Epoch 62/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5512 - val_accuracy: 0.7262 - val_loss: 0.5604\n",
            "Epoch 63/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5593 - val_accuracy: 0.7243 - val_loss: 0.5599\n",
            "Epoch 64/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.5594 - val_accuracy: 0.7264 - val_loss: 0.5603\n",
            "Epoch 65/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5515 - val_accuracy: 0.7261 - val_loss: 0.5595\n",
            "Epoch 66/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5585 - val_accuracy: 0.7239 - val_loss: 0.5630\n",
            "Epoch 67/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5575 - val_accuracy: 0.7245 - val_loss: 0.5606\n",
            "Epoch 68/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5508 - val_accuracy: 0.7235 - val_loss: 0.5608\n",
            "Epoch 69/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.5584 - val_accuracy: 0.7243 - val_loss: 0.5607\n",
            "Epoch 70/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5532 - val_accuracy: 0.7255 - val_loss: 0.5602\n",
            "Epoch 71/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5552 - val_accuracy: 0.7284 - val_loss: 0.5593\n",
            "Epoch 72/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5565 - val_accuracy: 0.7239 - val_loss: 0.5612\n",
            "Epoch 73/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.5491 - val_accuracy: 0.7258 - val_loss: 0.5599\n",
            "Epoch 74/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.5545 - val_accuracy: 0.7277 - val_loss: 0.5599\n",
            "Epoch 75/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5600 - val_accuracy: 0.7238 - val_loss: 0.5606\n",
            "Epoch 76/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5525 - val_accuracy: 0.7239 - val_loss: 0.5612\n",
            "Epoch 77/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5589 - val_accuracy: 0.7292 - val_loss: 0.5613\n",
            "Epoch 78/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5542 - val_accuracy: 0.7245 - val_loss: 0.5631\n",
            "Epoch 79/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5515 - val_accuracy: 0.7251 - val_loss: 0.5615\n",
            "Epoch 80/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5568 - val_accuracy: 0.7258 - val_loss: 0.5638\n",
            "Epoch 81/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5554 - val_accuracy: 0.7241 - val_loss: 0.5606\n",
            "Epoch 82/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5547 - val_accuracy: 0.7274 - val_loss: 0.5597\n",
            "Epoch 83/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5573 - val_accuracy: 0.7267 - val_loss: 0.5611\n",
            "Epoch 84/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5572 - val_accuracy: 0.7258 - val_loss: 0.5606\n",
            "Epoch 85/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7373 - loss: 0.5449 - val_accuracy: 0.7264 - val_loss: 0.5608\n",
            "Epoch 86/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5570 - val_accuracy: 0.7249 - val_loss: 0.5603\n",
            "Epoch 87/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5521 - val_accuracy: 0.7229 - val_loss: 0.5617\n",
            "Epoch 88/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5589 - val_accuracy: 0.7246 - val_loss: 0.5601\n",
            "Epoch 89/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5559 - val_accuracy: 0.7242 - val_loss: 0.5645\n",
            "Epoch 90/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5559 - val_accuracy: 0.7243 - val_loss: 0.5602\n",
            "Epoch 91/150\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5584 - val_accuracy: 0.7241 - val_loss: 0.5631\n",
            "215/215 - 0s - 1ms/step - accuracy: 0.7284 - loss: 0.5593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Loss: 0.5593271255493164, Optimized Accuracy: 0.7284256815910339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Hyperparameter tuning for number of neurons and dropout rate\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
        "                    input_dim=input_features,\n",
        "                    activation='tanh'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(units=hp.Int('units_2', min_value=16, max_value=64, step=16),\n",
        "                    activation='tanh'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Hyperparameter tuning for learning rate\n",
        "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the tuner\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=10,  # Number of model configurations to try\n",
        "                        executions_per_trial=3,  # Number of times to train each model\n",
        "                        directory='keras_tuner_dir',\n",
        "                        project_name='AlphabetSoup')\n",
        "\n",
        "# Run the tuner\n",
        "tuner.search(X_train_resampled, y_train_resampled, epochs=150, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Best model accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzgyMJ21PF6k",
        "outputId": "94ff2129-40e1-424c-feb0-6a2d6bfe52d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from keras_tuner_dir/AlphabetSoup/tuner0.json\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "96                |96                |units\n",
            "0.3               |0.3               |dropout\n",
            "48                |16                |units_2\n",
            "0.4               |0.1               |dropout_2\n",
            "0.001             |0.001             |learning_rate\n",
            "\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6711 - loss: 0.6297 - val_accuracy: 0.7178 - val_loss: 0.5725\n",
            "Epoch 2/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5843 - val_accuracy: 0.7246 - val_loss: 0.5701\n",
            "Epoch 3/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5672 - val_accuracy: 0.7258 - val_loss: 0.5644\n",
            "Epoch 4/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5677 - val_accuracy: 0.7243 - val_loss: 0.5639\n",
            "Epoch 5/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.5623 - val_accuracy: 0.7249 - val_loss: 0.5626\n",
            "Epoch 6/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5656 - val_accuracy: 0.7243 - val_loss: 0.5616\n",
            "Epoch 7/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5643 - val_accuracy: 0.7265 - val_loss: 0.5639\n",
            "Epoch 8/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5564 - val_accuracy: 0.7254 - val_loss: 0.5611\n",
            "Epoch 9/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.5575 - val_accuracy: 0.7271 - val_loss: 0.5580\n",
            "Epoch 10/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5605 - val_accuracy: 0.7289 - val_loss: 0.5593\n",
            "Epoch 11/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5582 - val_accuracy: 0.7286 - val_loss: 0.5582\n",
            "Epoch 12/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5562 - val_accuracy: 0.7248 - val_loss: 0.5575\n",
            "Epoch 13/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5559 - val_accuracy: 0.7257 - val_loss: 0.5574\n",
            "Epoch 14/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5561 - val_accuracy: 0.7267 - val_loss: 0.5568\n",
            "Epoch 15/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.5548 - val_accuracy: 0.7236 - val_loss: 0.5561\n",
            "Epoch 16/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5561 - val_accuracy: 0.7267 - val_loss: 0.5578\n",
            "Epoch 17/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5531 - val_accuracy: 0.7243 - val_loss: 0.5561\n",
            "Epoch 18/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5573 - val_accuracy: 0.7252 - val_loss: 0.5561\n",
            "Epoch 19/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5506 - val_accuracy: 0.7252 - val_loss: 0.5556\n",
            "Epoch 20/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5500 - val_accuracy: 0.7241 - val_loss: 0.5563\n",
            "Epoch 21/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5517 - val_accuracy: 0.7249 - val_loss: 0.5578\n",
            "Epoch 22/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5509 - val_accuracy: 0.7248 - val_loss: 0.5559\n",
            "Epoch 23/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5551 - val_accuracy: 0.7241 - val_loss: 0.5553\n",
            "Epoch 24/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5502 - val_accuracy: 0.7230 - val_loss: 0.5566\n",
            "Epoch 25/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5538 - val_accuracy: 0.7241 - val_loss: 0.5552\n",
            "Epoch 26/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5502 - val_accuracy: 0.7246 - val_loss: 0.5544\n",
            "Epoch 27/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5566 - val_accuracy: 0.7245 - val_loss: 0.5560\n",
            "Epoch 28/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5519 - val_accuracy: 0.7268 - val_loss: 0.5548\n",
            "Epoch 29/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5490 - val_accuracy: 0.7283 - val_loss: 0.5550\n",
            "Epoch 30/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5527 - val_accuracy: 0.7262 - val_loss: 0.5562\n",
            "Epoch 31/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5558 - val_accuracy: 0.7296 - val_loss: 0.5550\n",
            "Epoch 32/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5529 - val_accuracy: 0.7264 - val_loss: 0.5541\n",
            "Epoch 33/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5523 - val_accuracy: 0.7292 - val_loss: 0.5541\n",
            "Epoch 34/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5494 - val_accuracy: 0.7278 - val_loss: 0.5537\n",
            "Epoch 35/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5512 - val_accuracy: 0.7262 - val_loss: 0.5534\n",
            "Epoch 36/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5496 - val_accuracy: 0.7262 - val_loss: 0.5552\n",
            "Epoch 37/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5480 - val_accuracy: 0.7267 - val_loss: 0.5550\n",
            "Epoch 38/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.5567 - val_accuracy: 0.7292 - val_loss: 0.5538\n",
            "Epoch 39/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5492 - val_accuracy: 0.7280 - val_loss: 0.5549\n",
            "Epoch 40/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5460 - val_accuracy: 0.7284 - val_loss: 0.5541\n",
            "Epoch 41/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5450 - val_accuracy: 0.7268 - val_loss: 0.5537\n",
            "Epoch 42/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5511 - val_accuracy: 0.7290 - val_loss: 0.5557\n",
            "Epoch 43/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5531 - val_accuracy: 0.7290 - val_loss: 0.5553\n",
            "Epoch 44/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5508 - val_accuracy: 0.7267 - val_loss: 0.5547\n",
            "Epoch 45/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5475 - val_accuracy: 0.7303 - val_loss: 0.5543\n",
            "Epoch 46/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5537 - val_accuracy: 0.7259 - val_loss: 0.5536\n",
            "Epoch 47/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5486 - val_accuracy: 0.7296 - val_loss: 0.5534\n",
            "Epoch 48/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5539 - val_accuracy: 0.7283 - val_loss: 0.5549\n",
            "Epoch 49/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5508 - val_accuracy: 0.7290 - val_loss: 0.5541\n",
            "Epoch 50/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5504 - val_accuracy: 0.7270 - val_loss: 0.5535\n",
            "Epoch 51/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5486 - val_accuracy: 0.7265 - val_loss: 0.5540\n",
            "Epoch 52/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5482 - val_accuracy: 0.7262 - val_loss: 0.5556\n",
            "Epoch 53/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.5513 - val_accuracy: 0.7264 - val_loss: 0.5544\n",
            "Epoch 54/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5537 - val_accuracy: 0.7306 - val_loss: 0.5538\n",
            "Epoch 55/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5483 - val_accuracy: 0.7290 - val_loss: 0.5543\n",
            "Epoch 56/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5530 - val_accuracy: 0.7286 - val_loss: 0.5536\n",
            "Epoch 57/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5453 - val_accuracy: 0.7264 - val_loss: 0.5530\n",
            "Epoch 58/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5493 - val_accuracy: 0.7286 - val_loss: 0.5528\n",
            "Epoch 59/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5454 - val_accuracy: 0.7257 - val_loss: 0.5541\n",
            "Epoch 60/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5514 - val_accuracy: 0.7277 - val_loss: 0.5523\n",
            "Epoch 61/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5566 - val_accuracy: 0.7290 - val_loss: 0.5538\n",
            "Epoch 62/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5488 - val_accuracy: 0.7274 - val_loss: 0.5528\n",
            "Epoch 63/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5470 - val_accuracy: 0.7270 - val_loss: 0.5541\n",
            "Epoch 64/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5478 - val_accuracy: 0.7296 - val_loss: 0.5531\n",
            "Epoch 65/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5459 - val_accuracy: 0.7265 - val_loss: 0.5536\n",
            "Epoch 66/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5464 - val_accuracy: 0.7262 - val_loss: 0.5539\n",
            "Epoch 67/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5466 - val_accuracy: 0.7293 - val_loss: 0.5534\n",
            "Epoch 68/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.5498 - val_accuracy: 0.7265 - val_loss: 0.5545\n",
            "Epoch 69/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5474 - val_accuracy: 0.7267 - val_loss: 0.5537\n",
            "Epoch 70/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5458 - val_accuracy: 0.7258 - val_loss: 0.5542\n",
            "Epoch 71/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5458 - val_accuracy: 0.7265 - val_loss: 0.5539\n",
            "Epoch 72/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5490 - val_accuracy: 0.7264 - val_loss: 0.5543\n",
            "Epoch 73/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5442 - val_accuracy: 0.7264 - val_loss: 0.5546\n",
            "Epoch 74/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5502 - val_accuracy: 0.7264 - val_loss: 0.5530\n",
            "Epoch 75/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5406 - val_accuracy: 0.7276 - val_loss: 0.5537\n",
            "Epoch 76/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5531 - val_accuracy: 0.7265 - val_loss: 0.5531\n",
            "Epoch 77/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5431 - val_accuracy: 0.7261 - val_loss: 0.5527\n",
            "Epoch 78/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5513 - val_accuracy: 0.7264 - val_loss: 0.5551\n",
            "Epoch 79/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5495 - val_accuracy: 0.7287 - val_loss: 0.5532\n",
            "Epoch 80/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5500 - val_accuracy: 0.7294 - val_loss: 0.5536\n",
            "Epoch 81/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5467 - val_accuracy: 0.7265 - val_loss: 0.5537\n",
            "Epoch 82/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5431 - val_accuracy: 0.7283 - val_loss: 0.5522\n",
            "Epoch 83/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.5516 - val_accuracy: 0.7296 - val_loss: 0.5529\n",
            "Epoch 84/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5530 - val_accuracy: 0.7286 - val_loss: 0.5544\n",
            "Epoch 85/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5471 - val_accuracy: 0.7297 - val_loss: 0.5540\n",
            "Epoch 86/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5453 - val_accuracy: 0.7259 - val_loss: 0.5539\n",
            "Epoch 87/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5490 - val_accuracy: 0.7268 - val_loss: 0.5533\n",
            "Epoch 88/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5438 - val_accuracy: 0.7264 - val_loss: 0.5531\n",
            "Epoch 89/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5389 - val_accuracy: 0.7273 - val_loss: 0.5535\n",
            "Epoch 90/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5518 - val_accuracy: 0.7309 - val_loss: 0.5523\n",
            "Epoch 91/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5527 - val_accuracy: 0.7287 - val_loss: 0.5535\n",
            "Epoch 92/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5466 - val_accuracy: 0.7296 - val_loss: 0.5536\n",
            "Epoch 93/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5430 - val_accuracy: 0.7289 - val_loss: 0.5540\n",
            "Epoch 94/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5416 - val_accuracy: 0.7265 - val_loss: 0.5539\n",
            "Epoch 95/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5463 - val_accuracy: 0.7252 - val_loss: 0.5531\n",
            "Epoch 96/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.5500 - val_accuracy: 0.7296 - val_loss: 0.5540\n",
            "Epoch 97/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5445 - val_accuracy: 0.7299 - val_loss: 0.5530\n",
            "Epoch 98/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5433 - val_accuracy: 0.7252 - val_loss: 0.5549\n",
            "Epoch 99/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5429 - val_accuracy: 0.7289 - val_loss: 0.5535\n",
            "Epoch 100/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.5453 - val_accuracy: 0.7264 - val_loss: 0.5535\n",
            "Epoch 101/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5439 - val_accuracy: 0.7281 - val_loss: 0.5538\n",
            "Epoch 102/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.5427 - val_accuracy: 0.7261 - val_loss: 0.5548\n",
            "Epoch 103/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.5406 - val_accuracy: 0.7286 - val_loss: 0.5537\n",
            "Epoch 104/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5490 - val_accuracy: 0.7313 - val_loss: 0.5532\n",
            "Epoch 105/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5522 - val_accuracy: 0.7286 - val_loss: 0.5540\n",
            "Epoch 106/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5482 - val_accuracy: 0.7300 - val_loss: 0.5540\n",
            "Epoch 107/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5431 - val_accuracy: 0.7267 - val_loss: 0.5544\n",
            "Epoch 108/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5458 - val_accuracy: 0.7309 - val_loss: 0.5539\n",
            "Epoch 109/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5484 - val_accuracy: 0.7262 - val_loss: 0.5554\n",
            "Epoch 110/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5456 - val_accuracy: 0.7300 - val_loss: 0.5549\n",
            "Epoch 111/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5470 - val_accuracy: 0.7309 - val_loss: 0.5551\n",
            "Epoch 112/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.5480 - val_accuracy: 0.7305 - val_loss: 0.5529\n",
            "Epoch 113/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5456 - val_accuracy: 0.7277 - val_loss: 0.5537\n",
            "Epoch 114/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5459 - val_accuracy: 0.7292 - val_loss: 0.5530\n",
            "Epoch 115/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5492 - val_accuracy: 0.7286 - val_loss: 0.5550\n",
            "Epoch 116/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5454 - val_accuracy: 0.7243 - val_loss: 0.5544\n",
            "Epoch 117/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5463 - val_accuracy: 0.7252 - val_loss: 0.5531\n",
            "Epoch 118/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5455 - val_accuracy: 0.7281 - val_loss: 0.5522\n",
            "Epoch 119/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5481 - val_accuracy: 0.7270 - val_loss: 0.5543\n",
            "Epoch 120/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5447 - val_accuracy: 0.7308 - val_loss: 0.5523\n",
            "Epoch 121/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5474 - val_accuracy: 0.7276 - val_loss: 0.5547\n",
            "Epoch 122/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5433 - val_accuracy: 0.7261 - val_loss: 0.5555\n",
            "Epoch 123/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5469 - val_accuracy: 0.7296 - val_loss: 0.5537\n",
            "Epoch 124/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5455 - val_accuracy: 0.7262 - val_loss: 0.5529\n",
            "Epoch 125/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5479 - val_accuracy: 0.7271 - val_loss: 0.5537\n",
            "Epoch 126/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.5430 - val_accuracy: 0.7283 - val_loss: 0.5529\n",
            "Epoch 127/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5460 - val_accuracy: 0.7262 - val_loss: 0.5536\n",
            "Epoch 128/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5431 - val_accuracy: 0.7254 - val_loss: 0.5534\n",
            "Epoch 129/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5439 - val_accuracy: 0.7274 - val_loss: 0.5536\n",
            "Epoch 130/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5413 - val_accuracy: 0.7265 - val_loss: 0.5533\n",
            "Epoch 131/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5432 - val_accuracy: 0.7249 - val_loss: 0.5557\n",
            "Epoch 132/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5482 - val_accuracy: 0.7254 - val_loss: 0.5539\n",
            "Epoch 133/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5472 - val_accuracy: 0.7242 - val_loss: 0.5542\n",
            "Epoch 134/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5443 - val_accuracy: 0.7287 - val_loss: 0.5526\n",
            "Epoch 135/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5461 - val_accuracy: 0.7268 - val_loss: 0.5540\n",
            "Epoch 136/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5460 - val_accuracy: 0.7236 - val_loss: 0.5531\n",
            "Epoch 137/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5429 - val_accuracy: 0.7261 - val_loss: 0.5541\n",
            "Epoch 138/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5444 - val_accuracy: 0.7262 - val_loss: 0.5539\n",
            "Epoch 139/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5445 - val_accuracy: 0.7255 - val_loss: 0.5551\n",
            "Epoch 140/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5404 - val_accuracy: 0.7264 - val_loss: 0.5535\n",
            "Epoch 141/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5468 - val_accuracy: 0.7290 - val_loss: 0.5531\n",
            "Epoch 142/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5462 - val_accuracy: 0.7290 - val_loss: 0.5533\n",
            "Epoch 143/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5455 - val_accuracy: 0.7267 - val_loss: 0.5556\n",
            "Epoch 144/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5507 - val_accuracy: 0.7280 - val_loss: 0.5529\n",
            "Epoch 145/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5412 - val_accuracy: 0.7271 - val_loss: 0.5534\n",
            "Epoch 146/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5462 - val_accuracy: 0.7289 - val_loss: 0.5526\n",
            "Epoch 147/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5452 - val_accuracy: 0.7276 - val_loss: 0.5532\n",
            "Epoch 148/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5386 - val_accuracy: 0.7257 - val_loss: 0.5539\n",
            "Epoch 149/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5449 - val_accuracy: 0.7268 - val_loss: 0.5544\n",
            "Epoch 150/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.5430 - val_accuracy: 0.7277 - val_loss: 0.5540\n",
            "Epoch 1/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.6148 - val_accuracy: 0.7190 - val_loss: 0.5720\n",
            "Epoch 2/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5718 - val_accuracy: 0.7249 - val_loss: 0.5664\n",
            "Epoch 3/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5678 - val_accuracy: 0.7235 - val_loss: 0.5652\n",
            "Epoch 4/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5660 - val_accuracy: 0.7273 - val_loss: 0.5633\n",
            "Epoch 5/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5642 - val_accuracy: 0.7245 - val_loss: 0.5608\n",
            "Epoch 6/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5605 - val_accuracy: 0.7239 - val_loss: 0.5623\n",
            "Epoch 7/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5656 - val_accuracy: 0.7278 - val_loss: 0.5594\n",
            "Epoch 8/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5541 - val_accuracy: 0.7268 - val_loss: 0.5615\n",
            "Epoch 9/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5602 - val_accuracy: 0.7276 - val_loss: 0.5573\n",
            "Epoch 10/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5550 - val_accuracy: 0.7239 - val_loss: 0.5570\n",
            "Epoch 11/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5584 - val_accuracy: 0.7252 - val_loss: 0.5575\n",
            "Epoch 12/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.5564 - val_accuracy: 0.7289 - val_loss: 0.5576\n",
            "Epoch 13/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5626 - val_accuracy: 0.7280 - val_loss: 0.5568\n",
            "Epoch 14/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5573 - val_accuracy: 0.7276 - val_loss: 0.5552\n",
            "Epoch 15/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5578 - val_accuracy: 0.7254 - val_loss: 0.5560\n",
            "Epoch 16/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.5598 - val_accuracy: 0.7254 - val_loss: 0.5547\n",
            "Epoch 17/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5511 - val_accuracy: 0.7245 - val_loss: 0.5544\n",
            "Epoch 18/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5565 - val_accuracy: 0.7258 - val_loss: 0.5552\n",
            "Epoch 19/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5538 - val_accuracy: 0.7289 - val_loss: 0.5545\n",
            "Epoch 20/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7254 - loss: 0.5566 - val_accuracy: 0.7273 - val_loss: 0.5540\n",
            "Epoch 21/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5517 - val_accuracy: 0.7265 - val_loss: 0.5549\n",
            "Epoch 22/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5502 - val_accuracy: 0.7264 - val_loss: 0.5551\n",
            "Epoch 23/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5525 - val_accuracy: 0.7254 - val_loss: 0.5552\n",
            "Epoch 24/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5492 - val_accuracy: 0.7229 - val_loss: 0.5554\n",
            "Epoch 25/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5535 - val_accuracy: 0.7302 - val_loss: 0.5549\n",
            "Epoch 26/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5503 - val_accuracy: 0.7262 - val_loss: 0.5533\n",
            "Epoch 27/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5509 - val_accuracy: 0.7286 - val_loss: 0.5539\n",
            "Epoch 28/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5504 - val_accuracy: 0.7268 - val_loss: 0.5540\n",
            "Epoch 29/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5474 - val_accuracy: 0.7303 - val_loss: 0.5532\n",
            "Epoch 30/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5511 - val_accuracy: 0.7243 - val_loss: 0.5540\n",
            "Epoch 31/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5524 - val_accuracy: 0.7283 - val_loss: 0.5548\n",
            "Epoch 32/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5487 - val_accuracy: 0.7267 - val_loss: 0.5538\n",
            "Epoch 33/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5528 - val_accuracy: 0.7262 - val_loss: 0.5545\n",
            "Epoch 34/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5550 - val_accuracy: 0.7262 - val_loss: 0.5553\n",
            "Epoch 35/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5515 - val_accuracy: 0.7252 - val_loss: 0.5539\n",
            "Epoch 36/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5532 - val_accuracy: 0.7262 - val_loss: 0.5534\n",
            "Epoch 37/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5476 - val_accuracy: 0.7297 - val_loss: 0.5534\n",
            "Epoch 38/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5546 - val_accuracy: 0.7318 - val_loss: 0.5532\n",
            "Epoch 39/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5505 - val_accuracy: 0.7305 - val_loss: 0.5530\n",
            "Epoch 40/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5452 - val_accuracy: 0.7265 - val_loss: 0.5554\n",
            "Epoch 41/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.5556 - val_accuracy: 0.7262 - val_loss: 0.5524\n",
            "Epoch 42/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5500 - val_accuracy: 0.7299 - val_loss: 0.5532\n",
            "Epoch 43/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5517 - val_accuracy: 0.7278 - val_loss: 0.5564\n",
            "Epoch 44/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5499 - val_accuracy: 0.7271 - val_loss: 0.5530\n",
            "Epoch 45/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5460 - val_accuracy: 0.7293 - val_loss: 0.5535\n",
            "Epoch 46/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5464 - val_accuracy: 0.7296 - val_loss: 0.5535\n",
            "Epoch 47/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5483 - val_accuracy: 0.7283 - val_loss: 0.5536\n",
            "Epoch 48/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5535 - val_accuracy: 0.7265 - val_loss: 0.5528\n",
            "Epoch 49/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5482 - val_accuracy: 0.7265 - val_loss: 0.5541\n",
            "Epoch 50/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5475 - val_accuracy: 0.7280 - val_loss: 0.5527\n",
            "Epoch 51/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5510 - val_accuracy: 0.7270 - val_loss: 0.5539\n",
            "Epoch 52/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5467 - val_accuracy: 0.7259 - val_loss: 0.5534\n",
            "Epoch 53/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5466 - val_accuracy: 0.7299 - val_loss: 0.5529\n",
            "Epoch 54/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5481 - val_accuracy: 0.7273 - val_loss: 0.5531\n",
            "Epoch 55/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.5517 - val_accuracy: 0.7278 - val_loss: 0.5531\n",
            "Epoch 56/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5500 - val_accuracy: 0.7274 - val_loss: 0.5520\n",
            "Epoch 57/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5453 - val_accuracy: 0.7310 - val_loss: 0.5524\n",
            "Epoch 58/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5528 - val_accuracy: 0.7280 - val_loss: 0.5523\n",
            "Epoch 59/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5503 - val_accuracy: 0.7258 - val_loss: 0.5525\n",
            "Epoch 60/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5503 - val_accuracy: 0.7299 - val_loss: 0.5538\n",
            "Epoch 61/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5456 - val_accuracy: 0.7268 - val_loss: 0.5527\n",
            "Epoch 62/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5474 - val_accuracy: 0.7293 - val_loss: 0.5531\n",
            "Epoch 63/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5463 - val_accuracy: 0.7309 - val_loss: 0.5531\n",
            "Epoch 64/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5478 - val_accuracy: 0.7302 - val_loss: 0.5530\n",
            "Epoch 65/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.5487 - val_accuracy: 0.7267 - val_loss: 0.5529\n",
            "Epoch 66/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.5447 - val_accuracy: 0.7264 - val_loss: 0.5524\n",
            "Epoch 67/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5509 - val_accuracy: 0.7294 - val_loss: 0.5548\n",
            "Epoch 68/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5525 - val_accuracy: 0.7297 - val_loss: 0.5513\n",
            "Epoch 69/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5442 - val_accuracy: 0.7287 - val_loss: 0.5515\n",
            "Epoch 70/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5532 - val_accuracy: 0.7264 - val_loss: 0.5519\n",
            "Epoch 71/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5483 - val_accuracy: 0.7273 - val_loss: 0.5519\n",
            "Epoch 72/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5484 - val_accuracy: 0.7270 - val_loss: 0.5538\n",
            "Epoch 73/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.5437 - val_accuracy: 0.7271 - val_loss: 0.5524\n",
            "Epoch 74/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5484 - val_accuracy: 0.7284 - val_loss: 0.5545\n",
            "Epoch 75/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5523 - val_accuracy: 0.7309 - val_loss: 0.5526\n",
            "Epoch 76/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5479 - val_accuracy: 0.7296 - val_loss: 0.5525\n",
            "Epoch 77/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5447 - val_accuracy: 0.7261 - val_loss: 0.5520\n",
            "Epoch 78/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5477 - val_accuracy: 0.7292 - val_loss: 0.5530\n",
            "Epoch 79/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5469 - val_accuracy: 0.7268 - val_loss: 0.5516\n",
            "Epoch 80/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5477 - val_accuracy: 0.7277 - val_loss: 0.5538\n",
            "Epoch 81/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5447 - val_accuracy: 0.7259 - val_loss: 0.5537\n",
            "Epoch 82/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5426 - val_accuracy: 0.7268 - val_loss: 0.5535\n",
            "Epoch 83/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5431 - val_accuracy: 0.7289 - val_loss: 0.5531\n",
            "Epoch 84/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5442 - val_accuracy: 0.7281 - val_loss: 0.5552\n",
            "Epoch 85/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5454 - val_accuracy: 0.7261 - val_loss: 0.5534\n",
            "Epoch 86/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5482 - val_accuracy: 0.7284 - val_loss: 0.5529\n",
            "Epoch 87/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5429 - val_accuracy: 0.7284 - val_loss: 0.5524\n",
            "Epoch 88/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5457 - val_accuracy: 0.7243 - val_loss: 0.5527\n",
            "Epoch 89/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5438 - val_accuracy: 0.7245 - val_loss: 0.5543\n",
            "Epoch 90/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5489 - val_accuracy: 0.7267 - val_loss: 0.5536\n",
            "Epoch 91/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5445 - val_accuracy: 0.7271 - val_loss: 0.5531\n",
            "Epoch 92/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5500 - val_accuracy: 0.7232 - val_loss: 0.5538\n",
            "Epoch 93/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5464 - val_accuracy: 0.7289 - val_loss: 0.5531\n",
            "Epoch 94/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5431 - val_accuracy: 0.7289 - val_loss: 0.5532\n",
            "Epoch 95/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5461 - val_accuracy: 0.7248 - val_loss: 0.5543\n",
            "Epoch 96/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.5530 - val_accuracy: 0.7270 - val_loss: 0.5546\n",
            "Epoch 97/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5406 - val_accuracy: 0.7276 - val_loss: 0.5550\n",
            "Epoch 98/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5477 - val_accuracy: 0.7286 - val_loss: 0.5533\n",
            "Epoch 99/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5378 - val_accuracy: 0.7262 - val_loss: 0.5531\n",
            "Epoch 100/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5413 - val_accuracy: 0.7270 - val_loss: 0.5530\n",
            "Epoch 101/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.5475 - val_accuracy: 0.7264 - val_loss: 0.5526\n",
            "Epoch 102/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5486 - val_accuracy: 0.7239 - val_loss: 0.5533\n",
            "Epoch 103/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5464 - val_accuracy: 0.7252 - val_loss: 0.5551\n",
            "Epoch 104/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5473 - val_accuracy: 0.7294 - val_loss: 0.5551\n",
            "Epoch 105/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5512 - val_accuracy: 0.7268 - val_loss: 0.5550\n",
            "Epoch 106/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5522 - val_accuracy: 0.7286 - val_loss: 0.5543\n",
            "Epoch 107/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5478 - val_accuracy: 0.7259 - val_loss: 0.5532\n",
            "Epoch 108/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5468 - val_accuracy: 0.7296 - val_loss: 0.5526\n",
            "Epoch 109/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5474 - val_accuracy: 0.7255 - val_loss: 0.5534\n",
            "Epoch 110/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.5460 - val_accuracy: 0.7280 - val_loss: 0.5551\n",
            "Epoch 111/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5434 - val_accuracy: 0.7255 - val_loss: 0.5551\n",
            "Epoch 112/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.5460 - val_accuracy: 0.7254 - val_loss: 0.5520\n",
            "Epoch 113/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5449 - val_accuracy: 0.7235 - val_loss: 0.5533\n",
            "Epoch 114/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5437 - val_accuracy: 0.7254 - val_loss: 0.5542\n",
            "Epoch 115/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5430 - val_accuracy: 0.7236 - val_loss: 0.5528\n",
            "Epoch 116/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5467 - val_accuracy: 0.7287 - val_loss: 0.5526\n",
            "Epoch 117/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.5449 - val_accuracy: 0.7258 - val_loss: 0.5531\n",
            "Epoch 118/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5418 - val_accuracy: 0.7255 - val_loss: 0.5534\n",
            "Epoch 119/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5461 - val_accuracy: 0.7251 - val_loss: 0.5518\n",
            "Epoch 120/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.5437 - val_accuracy: 0.7293 - val_loss: 0.5515\n",
            "Epoch 121/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5482 - val_accuracy: 0.7273 - val_loss: 0.5530\n",
            "Epoch 122/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5467 - val_accuracy: 0.7290 - val_loss: 0.5532\n",
            "Epoch 123/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5401 - val_accuracy: 0.7289 - val_loss: 0.5520\n",
            "Epoch 124/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5433 - val_accuracy: 0.7280 - val_loss: 0.5527\n",
            "Epoch 125/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.5459 - val_accuracy: 0.7289 - val_loss: 0.5536\n",
            "Epoch 126/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5449 - val_accuracy: 0.7303 - val_loss: 0.5537\n",
            "Epoch 127/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5503 - val_accuracy: 0.7286 - val_loss: 0.5516\n",
            "Epoch 128/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5480 - val_accuracy: 0.7287 - val_loss: 0.5515\n",
            "Epoch 129/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.5535 - val_accuracy: 0.7264 - val_loss: 0.5527\n",
            "Epoch 130/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.5473 - val_accuracy: 0.7293 - val_loss: 0.5522\n",
            "Epoch 131/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5433 - val_accuracy: 0.7246 - val_loss: 0.5521\n",
            "Epoch 132/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5454 - val_accuracy: 0.7257 - val_loss: 0.5535\n",
            "Epoch 133/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7271 - loss: 0.5476 - val_accuracy: 0.7243 - val_loss: 0.5536\n",
            "Epoch 134/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5454 - val_accuracy: 0.7293 - val_loss: 0.5544\n",
            "Epoch 135/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.5448 - val_accuracy: 0.7292 - val_loss: 0.5516\n",
            "Epoch 136/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5450 - val_accuracy: 0.7242 - val_loss: 0.5541\n",
            "Epoch 137/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5474 - val_accuracy: 0.7261 - val_loss: 0.5522\n",
            "Epoch 138/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5467 - val_accuracy: 0.7294 - val_loss: 0.5515\n",
            "Epoch 139/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5446 - val_accuracy: 0.7258 - val_loss: 0.5531\n",
            "Epoch 140/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5411 - val_accuracy: 0.7265 - val_loss: 0.5532\n",
            "Epoch 141/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5505 - val_accuracy: 0.7255 - val_loss: 0.5517\n",
            "Epoch 142/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5437 - val_accuracy: 0.7277 - val_loss: 0.5516\n",
            "Epoch 143/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5450 - val_accuracy: 0.7248 - val_loss: 0.5521\n",
            "Epoch 144/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5424 - val_accuracy: 0.7262 - val_loss: 0.5528\n",
            "Epoch 145/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5402 - val_accuracy: 0.7277 - val_loss: 0.5528\n",
            "Epoch 146/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5418 - val_accuracy: 0.7257 - val_loss: 0.5531\n",
            "Epoch 147/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5465 - val_accuracy: 0.7278 - val_loss: 0.5557\n",
            "Epoch 148/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.5492 - val_accuracy: 0.7259 - val_loss: 0.5518\n",
            "Epoch 149/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5443 - val_accuracy: 0.7267 - val_loss: 0.5517\n",
            "Epoch 150/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5420 - val_accuracy: 0.7305 - val_loss: 0.5528\n",
            "Epoch 1/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.6201 - val_accuracy: 0.7198 - val_loss: 0.5764\n",
            "Epoch 2/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5774 - val_accuracy: 0.7208 - val_loss: 0.5681\n",
            "Epoch 3/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5690 - val_accuracy: 0.7251 - val_loss: 0.5642\n",
            "Epoch 4/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5627 - val_accuracy: 0.7203 - val_loss: 0.5683\n",
            "Epoch 5/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.5645 - val_accuracy: 0.7251 - val_loss: 0.5598\n",
            "Epoch 6/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5632 - val_accuracy: 0.7251 - val_loss: 0.5604\n",
            "Epoch 7/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.5550 - val_accuracy: 0.7251 - val_loss: 0.5602\n",
            "Epoch 8/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7236 - loss: 0.5635 - val_accuracy: 0.7267 - val_loss: 0.5592\n",
            "Epoch 9/150\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5543 - val_accuracy: 0.7239 - val_loss: 0.5589\n",
            "Epoch 10/150\n",
            "\u001b[1m610/913\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5556"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "awrnSgQCOvqU"
      }
    }
  ]
}